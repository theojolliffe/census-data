{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 478,
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import networkx as nx\n",
    "from networkx_query import search_nodes, search_edges\n",
    "import numpy as np\n",
    "import math"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "source": [
    "with open('/Users/theojolliffe/Documents/Wayback BBC/topicScoresOrder.json', 'r') as fp:\n",
    "    topicScoresOrder = json.load(fp)\n",
    "\n",
    "topicScoresOrder = {i: {i[0]: 1/(1+i[1]/10) for i in topicScoresOrder[i]} for i in topicScoresOrder}\n",
    "\n",
    "for i in topicScoresOrder.keys():\n",
    "    topicScoresOrder[i]['welsh'] = 0.1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "source": [
    "# COLLECT 2021 LAs\n",
    "\n",
    "las2021 = pd.read_csv('./pipeline_active/lookup/lad2015_lad2021.csv')\n",
    "las2021 = [x for x in las2021['parent'] if str(x) != 'nan']\n",
    "las2021 = list(set(las2021))\n",
    "\n",
    "lads = []\n",
    "for i in las2021:\n",
    "    try:\n",
    "        lads.append(json.load(open(f'/Users/theojolliffe/Documents/pipeline_active/final/json/place/{i}.json', 'rb')))\n",
    "    except FileNotFoundError:\n",
    "        print(i)\n",
    "        # pass\n",
    "\n",
    "# Remove tiny areas\n",
    "# lads = [lad for lad in lads if (lad['name'] != 'City of London')&(lad['name'] != 'Isle of Scilly')]\n",
    "\n",
    "for lad in lads:\n",
    "    lad['data']['agemed']['value']['change']['all'] = lad['data']['agemed']['value']['2011']['all']-lad['data']['agemed']['value']['2001']['all']\n",
    "    lad['data']['density']['value']['change']['all'] = lad['data']['density']['value']['2011']['all']-lad['data']['density']['value']['2001']['all']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "source": [
    "options = pd.read_csv('./csv/lists/places_2020.csv')\n",
    "areaType = pd.read_csv('/Users/theojolliffe/Documents/Census Data/censusAreaLookup.csv')\n",
    "typeLookup = {}\n",
    "for i in areaType.index:\n",
    "    typeLookup[areaType.iloc[i]['Name']]=areaType.iloc[i]['Group name']\n",
    "\n",
    "areas = []\n",
    "for i in options[\"code\"]:\n",
    "    try:\n",
    "        areas.append(json.load(open(f'/Users/theojolliffe/Documents/pipeline_active/final/json/place/{i}.json', 'rb')))\n",
    "    except FileNotFoundError:\n",
    "#         print(i)\n",
    "        pass\n",
    "\n",
    "for area in areas:\n",
    "    area['data']['agemed']['value']['change']['all'] = area['data']['agemed']['value']['2011']['all']-area['data']['agemed']['value']['2001']['all']\n",
    "    area['data']['density']['value']['change']['all'] = area['data']['density']['value']['2011']['all']-area['data']['density']['value']['2001']['all']\n",
    "\n",
    "# Seperate the areas by area type\n",
    "regions = []\n",
    "for i in areas:\n",
    "    if i['type']=='rgn':\n",
    "        regions.append(i)\n",
    "\n",
    "countries = []\n",
    "for i in areas:\n",
    "    if (i['type']=='ew')|(i['type']=='ctry'):\n",
    "        countries.append(i)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "source": [
    "# Transform the welsh language data\n",
    "\n",
    "for area in lads:\n",
    "    if area['parents'][0]['name']=='Wales':\n",
    "        x = area['data']['welsh']\n",
    "        for y in x.keys():\n",
    "            if y=='value':\n",
    "                for z in x[y].keys():\n",
    "                    if z=='change':\n",
    "                        x[y][z]['NoWelsh'] = round(((x[y]['2011']['NoWelsh'] - x[y]['2001']['NoWelsh'])/x[y]['2001']['NoWelsh'])*100, 2)\n",
    "                        x[y][z]['all'] = x[y][z]['AllOver3']\n",
    "                        del x[y][z]['AllOver3']\n",
    "                    else:\n",
    "                        x[y][z]['NoWelsh'] = x[y][z]['AllOver3'] - x[y][z]['SpeaksWelsh']\n",
    "                        x[y][z]['all'] = x[y][z]['AllOver3']\n",
    "                        del x[y][z]['AllOver3']\n",
    "\n",
    "for area in lads:\n",
    "    if area['parents'][0]['name']=='Wales':\n",
    "        x = area['data']['welsh']\n",
    "        for y in x.keys():\n",
    "            if y=='perc':\n",
    "                for z in x[y].keys():\n",
    "                    if z=='change':\n",
    "                        x[y][z]['NoWelsh'] = x[y]['2011']['NoWelsh'] - x[y]['2001']['NoWelsh']\n",
    "                        x[y][z]['all'] = x[y][z]['AllOver3']\n",
    "                        del x[y][z]['AllOver3']\n",
    "                        for w in x[y][z].keys():\n",
    "                            x[y][z][w] = round(x[y]['2011'][w]-x[y]['2001'][w], 2)\n",
    "                    else:\n",
    "                        x[y][z]['NoWelsh'] = x[y][z]['AllOver3'] - x[y][z]['SpeaksWelsh']\n",
    "                        x[y][z]['all'] = x[y][z]['AllOver3']\n",
    "                        del x[y][z]['AllOver3']\n",
    "                        for w in x[y][z].keys():\n",
    "                            x[y][z][w] = round((x[y][z][w]/x[y][z]['all'])*100, 2)\n",
    "\n",
    "for area in lads:\n",
    "    if area['parents'][0]['name']!='Wales':\n",
    "        x = area['data']['welsh']\n",
    "        for y in x.keys():\n",
    "            for z in x[y].keys():\n",
    "                x[y][z]['all'] = 1\n",
    "                del x[y][z]['AllOver3']\n",
    "                for w in x[y][z].keys():\n",
    "                    x[y][z][w] = x[y][z][w] = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "source": [
    "for area in lads:\n",
    "    x = area['data']\n",
    "    for a in x.keys():\n",
    "        for y in x[a].keys():\n",
    "            for z in x[a][y].keys():\n",
    "                for b in x[a][y][z].keys():\n",
    "                    if math.isinf(x[a][y][z][b]):\n",
    "                        x[a][y][z][b] = 'Inf'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "source": [
    "# Transform the welsh language data\n",
    "\n",
    "for area in countries:\n",
    "    if area['name']=='Wales':\n",
    "        x = area['data']['welsh']\n",
    "        for y in x.keys():\n",
    "            if y=='value':\n",
    "                for z in x[y].keys():\n",
    "                    if z=='change':\n",
    "                        x[y][z]['NoWelsh'] = round(((x[y]['2011']['NoWelsh'] - x[y]['2001']['NoWelsh'])/x[y]['2001']['NoWelsh'])*100, 2)\n",
    "                        x[y][z]['all'] = x[y][z]['AllOver3']\n",
    "                        del x[y][z]['AllOver3']\n",
    "                    else:\n",
    "                        x[y][z]['NoWelsh'] = x[y][z]['AllOver3'] - x[y][z]['SpeaksWelsh']\n",
    "                        x[y][z]['all'] = x[y][z]['AllOver3']\n",
    "                        del x[y][z]['AllOver3']\n",
    "\n",
    "for area in countries:\n",
    "    if area['name']=='Wales':\n",
    "        x = area['data']['welsh']\n",
    "        for y in x.keys():\n",
    "            if y=='perc':\n",
    "                for z in x[y].keys():\n",
    "                    if z=='change':\n",
    "                        x[y][z]['NoWelsh'] = x[y]['2011']['NoWelsh'] - x[y]['2001']['NoWelsh']\n",
    "                        x[y][z]['all'] = x[y][z]['AllOver3']\n",
    "                        del x[y][z]['AllOver3']\n",
    "                        for w in x[y][z].keys():\n",
    "                            x[y][z][w] = round(x[y]['2011'][w]-x[y]['2001'][w], 2)\n",
    "                    else:\n",
    "                        x[y][z]['NoWelsh'] = x[y][z]['AllOver3'] - x[y][z]['SpeaksWelsh']\n",
    "                        x[y][z]['all'] = x[y][z]['AllOver3']\n",
    "                        del x[y][z]['AllOver3']\n",
    "                        for w in x[y][z].keys():\n",
    "                            x[y][z][w] = round((x[y][z][w]/x[y][z]['all'])*100, 2)\n",
    "        \n",
    "for area in countries:\n",
    "    if area['name']!='Wales':\n",
    "        x = area['data']['welsh']\n",
    "        for y in x.keys():\n",
    "            for z in x[y].keys():\n",
    "                x[y][z]['all'] = 1\n",
    "                del x[y][z]['AllOver3']\n",
    "                for w in x[y][z].keys():\n",
    "                    x[y][z][w] = x[y][z][w] = 1\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "source": [
    "nameChanges = {\n",
    "    \"Herefordshire, County of\": \"Herefordshire\",\n",
    "    \"Bristol, City of\": \"Bristol\",\n",
    "    # \"City of London\": \"the City of London\",\n",
    "    # \"Isles of Scilly\": \"the Isles of Scilly\",\n",
    "    # \"Isle of Anglesey\": \"the Isle of Anglesey\",\n",
    "    \"Derbyshire Dales\": \"the Derbyshire Dales\",\n",
    "    \"Kingston upon Hull, City of\": \"Kingston upon Hull\",\n",
    "    # \"New Forest\": \"the New Forest\"\n",
    "}\n",
    "for lad in lads:\n",
    "    if lad['name'] in nameChanges.keys():\n",
    "        lad['name'] = nameChanges[lad['name']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "source": [
    "simiDF = pd.read_csv('/Users/theojolliffe/Documents/correspondinglocalauthoritiesv3r.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "source": [
    "noOfLads = {\"England\": 309, \"Wales\": 22}\n",
    "areaClassDF = pd.read_csv('/Users/theojolliffe/Documents/area-reports/src/data/censusAreaLookup.csv')\n",
    "areaClassDF.at[75, 'Code'] = \"E06000058\"\n",
    "areaClassLU = {\n",
    "    \"1a1r\": \"affluent suburban area\", \"1b1r\": \"affluent rural area\", \n",
    "    \"1b2r\": \"growing rural area\", \"2a1r\": \"city\", \n",
    "    \"2b1r\": \"area\", \"3a2r\": \"remote area\", \n",
    "    \"3a1r\": \"agricultural area\", \"3b1r\": \"coastal area\",\n",
    "    \"3b2r\": \"seaside  area\",\n",
    "    \"4a1r\": \"urban area\", \"5a1r\": \"cosmopolitan area\",\n",
    "    \"6a2r\": \"industrial area\", \"6a3r\": \"service economy area\",\n",
    "    \"6a1r\": \"industrial area\", \"7a1r\": \"rural area\",\n",
    "    \"7c2r\": \"affluent area\", \"7c1r\": \"affluent area\",\n",
    "    \"8a1r\": \"multi-cultural area\", \"8a2r\": \"urban area\",\n",
    "    \"8b1r\": \"suburban area\", \"8b2r\": \"suburban area\",\n",
    "}\n",
    "areaClassSuperLU = {\n",
    "    \"1r\": \"affluent area\",\n",
    "    \"2r\": \"urban area\",\n",
    "    \"3r\": \"rural area\",\n",
    "    \"4r\": \"multi-cultural area\",\n",
    "    \"5r\": \"cosmopolitan area\",\n",
    "    \"6r\": \"industrial area\",\n",
    "    \"7r\": \"suburban area\",\n",
    "    \"8r\": \"built up area\",\n",
    "}\n",
    "gssLookup = {\"E09\": \"London borough\", \"E08\": \"metropolitan district\", \"E07\": \"district\", \"E06\": \"unitary authority\", \"W06\": \"Welsh district\"}\n",
    "gssLookupShort = {\"E09\": \"borough\", \"E08\": \"district\", \"E07\": \"district\", \"E06\": \"unitary authority\", \"W06\": \"district\"}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "source": [
    "bbcReg = pd.read_csv('/Users/theojolliffe/Downloads/bbc_regions.csv')\n",
    "bbcRegLU = {}\n",
    "for i in bbcReg.index:\n",
    "    if bbcReg['areaCode'].iloc[i] in [lad['code'] for lad in lads]:\n",
    "        bbcRegLU[bbcReg['areaCode'].iloc[i]] = bbcReg['bbc_online'].iloc[i]\n",
    "bbcRegLU['E06000053'] = 'cornwall'\n",
    "bbcRegLU['E06000060'] = 'beds_bucks_and_herts'\n",
    "bbcRegLU['E09000001'] = 'london'\n",
    "bbcRegLU['E07000150'] = 'northamptonshire'\n",
    "bbcRegLU['E06000061'] = 'northamptonshire'\n",
    "bbcRegLU['E06000062'] = 'northamptonshire'\n",
    "\n",
    "regionsBBC = ['cumbria', 'lancashire', 'merseyside', 'manchester', 'tees', 'tyne_and_wear', 'Humberside', 'york_and_north_yorkshire', 'leeds_and_west_yorkshire', 'lincolnshire', 'south_yorkshire', 'birmingham_and_black_country', 'coventry_and_warwickshire', 'hereford_and_worcester', 'shropshire', 'stoke_and_staffordshire', 'derbyshire', 'leicester', 'northamptonshire', 'nottingham', 'bristol', 'cornwall', 'devon', 'gloucestershire', 'somerset', 'wiltshire', 'beds_bucks_and_herts', 'cambridgeshire', 'essex', 'norfolk', 'suffolk', 'berkshire', 'dorset', 'hampshire', 'oxford', 'kent', 'london', 'surrey', 'sussex']\n",
    "bbcNames = {\n",
    "     'derby': 'derbyshire', \n",
    "     'hereford and worcester': 'hereford_and_worcester',\n",
    "     'tyne and wear': 'tyne_and_wear',\n",
    "     'northampton': 'northamptonshire',\n",
    "     'liverpool': 'merseyside',\n",
    "     'coventry and warwickshire': 'coventry_and_warwickshire',\n",
    "     'humberside': 'Humberside',\n",
    "     'sheffield and south yorkshire': 'south_yorkshire',\n",
    "     'hampshire & isle of wight': 'hampshire',\n",
    "     'stoke and staffordshire': 'stoke_and_staffordshire',\n",
    "     'york & north yorkshire': 'york_and_north_yorkshire',\n",
    "     'birmingham and black country': 'birmingham_and_black_country',\n",
    "     'beds, bucks and herts': 'beds_bucks_and_herts',\n",
    "     'leeds and west yorkshire': 'leeds_and_west_yorkshire'\n",
    "}\n",
    "for i in bbcRegLU.keys():\n",
    "    bbcRegLU[i] = bbcRegLU[i].lower()\n",
    "    if bbcRegLU[i] not in regionsBBC:\n",
    "        try:\n",
    "            bbcRegLU[i] = bbcNames[bbcRegLU[i]]\n",
    "        except:\n",
    "            pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "source": [
    "tfidf = pd.read_csv('/Users/theojolliffe/Documents/Wayback BBC/BBCRegionalTFIDF.csv')\n",
    "tfidf = tfidf.set_index('Unnamed: 0')\n",
    "for i in tfidf.columns:\n",
    "    for j in tfidf[i].index:\n",
    "        tfidf[i].loc[j] = 1+100*tfidf[i].loc[j]\n",
    "tfidfLU = {}\n",
    "for i in regionsBBC:\n",
    "    tfidfLU[i]=tfidf.loc[i].to_dict()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "source": [
    "TFtopicLU = {\n",
    "    'health': 'health',\n",
    "    'racial': 'ethnicity',\n",
    "    'population': 'population',\n",
    "    'age': 'agemed',\n",
    "    'work': 'economic',\n",
    "    'commuter': 'travel',\n",
    "    'housing': 'tenure'\n",
    "}\n",
    "TFtopicRev = dict((TFtopicLU[x],x) for x in TFtopicLU)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "source": [
    "def this(lad):\n",
    "    return[l for l in lads if l['name']==lad][0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "source": [
    "topics = [{1: 'population', 2: 'value', 3: 'all'}, \n",
    "          {1: 'density', 2: 'value', 3: 'all'},\n",
    "          {1: 'agemed', 2: 'value', 3: 'all'},\n",
    "          {1: 'welsh', 2: 'perc', 3: 'SpeaksWelsh'},\n",
    "          {1: 'welsh', 2: 'perc', 3: 'all'},\n",
    "          {1: 'care', 2: 'perc', 3: '20to49hoursWeek'},\n",
    "          {1: 'care', 2: 'perc', 3: '40PlushoursWeek'},\n",
    "          {1: 'children', 2: 'perc', 3: 'NoKids'},\n",
    "          {1: 'children', 2: 'perc', 3: 'Kids'},\n",
    "          {1: 'children', 2: 'perc', 3: 'NonDepKids'},\n",
    "          {1: 'travel', 2: 'perc', 3: 'car_van'},\n",
    "          {1: 'travel', 2: 'perc', 3: 'bus'},\n",
    "          {1: 'travel', 2: 'perc', 3: 'home'},\n",
    "          {1: 'travel', 2: 'perc', 3: 'train_metro'},\n",
    "          {1: 'travel', 2: 'perc', 3: 'foot'},\n",
    "          {1: 'tenure', 2: 'perc', 3: 'rented_social'},\n",
    "          {1: 'tenure', 2: 'perc', 3: 'rented_private'},\n",
    "          {1: 'tenure', 2: 'perc', 3: 'owned'},\n",
    "          {1: 'religion', 2: 'perc', 3: 'Hindu'},\n",
    "          {1: 'religion', 2: 'perc', 3: 'Buddhist'},\n",
    "          {1: 'religion', 2: 'perc', 3: 'Jewish'},\n",
    "          {1: 'religion', 2: 'perc', 3: 'Christian'},\n",
    "          {1: 'religion', 2: 'perc', 3: 'Muslim'},\n",
    "          {1: 'religion', 2: 'perc', 3: 'Noreligion'},\n",
    "          {1: 'household', 2: 'perc', 3: 'OnePerson'},\n",
    "          {1: 'household', 2: 'perc', 3: 'Married'},\n",
    "          {1: 'household', 2: 'perc', 3: 'LoneParent'},\n",
    "          {1: 'household', 2: 'perc', 3: 'Cohabiting'},\n",
    "          {1: 'health', 2: 'perc', 3: 'bad'},\n",
    "          {1: 'health', 2: 'perc', 3: 'good'},\n",
    "          {1: 'ethnicity', 2: 'perc', 3: 'black'},\n",
    "          {1: 'ethnicity', 2: 'perc', 3: 'white'},\n",
    "          {1: 'ethnicity', 2: 'perc', 3: 'asian'},\n",
    "          {1: 'marital', 2: 'perc', 3: 'Married'},\n",
    "          {1: 'marital', 2: 'perc', 3: 'Seperated'},\n",
    "          {1: 'marital', 2: 'perc', 3: 'Single'},\n",
    "          {1: 'hoursworked', 2: 'perc', 3: 'Female1-15'},\n",
    "          {1: 'hoursworked', 2: 'perc', 3: 'Male1-15'},\n",
    "          {1: 'hoursworked', 2: 'perc', 3: 'Female49plus'},\n",
    "          {1: 'hoursworked', 2: 'perc', 3: 'Male49plus'},\n",
    "          {1: 'economic', 2: 'perc', 3: 'employee'},\n",
    "          {1: 'economic', 2: 'perc', 3: 'student'},\n",
    "          {1: 'economic', 2: 'perc', 3: 'unemployed'},\n",
    "          {1: 'economic', 2: 'perc', 3: 'self-employed'}]\n",
    "\n",
    "ladCodes = []\n",
    "for lad in lads:\n",
    "    ladCodes.append(lad['code'])\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame(columns=\n",
    "                  ['lad', '2001',  '2011',  'change', 'topic', 'parent'])\n",
    "for j in range(len(topics)):\n",
    "    df1 = pd.DataFrame(index=ladCodes, columns=\n",
    "                      ['lad', '2001',  '2011',  'change', 'topic', 'parent'])\n",
    "    for i in range(len(lads)):\n",
    "        df1['lad'].iloc[i] = lads[i]['name']\n",
    "        df1['2001'].iloc[i] = lads[i]['data'][topics[j][1]][topics[j][2]]['2001'][topics[j][3]]\n",
    "        df1['2011'].iloc[i] = lads[i]['data'][topics[j][1]][topics[j][2]]['2011'][topics[j][3]]    \n",
    "        df1['change'].iloc[i] = lads[i]['data'][topics[j][1]][topics[j][2]]['change'][topics[j][3]]\n",
    "        df1['topic'].iloc[i] = topics[j][1]+\"_\"+topics[j][3]\n",
    "        df1['parent'].iloc[i] = lads[i]['parents'][0]['name']\n",
    "    df = pd.concat([df,df1])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "source": [
    "this('Barking and Dagenham')['data']['care']['perc_rank']['change']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'1to19hoursWeek': 331.0,\n",
       " '20to49hoursWeek': 175.0,\n",
       " '40PlushoursWeek': 330.0,\n",
       " 'noCare': 1.0}"
      ]
     },
     "metadata": {},
     "execution_count": 493
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "source": [
    "df[df['topic'].map(lambda x: x.split(\"_\")[0] == 'care')].sort_values(['change'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                    lad  2001  2011 change  \\\n",
       "E09000030                 Tower Hamlets  2.38  1.93  -0.45   \n",
       "E09000002          Barking and Dagenham  2.69  2.49   -0.2   \n",
       "E09000001                City of London  1.14  0.95  -0.19   \n",
       "E09000025                        Newham   2.2  2.05  -0.15   \n",
       "E09000012                       Hackney  1.74  1.67  -0.07   \n",
       "...                                 ...   ...   ...    ...   \n",
       "E07000146  King's Lynn and West Norfolk  2.48  3.25   0.77   \n",
       "E07000076                      Tendring  2.77  3.54   0.77   \n",
       "E06000027                        Torbay  2.76  3.58   0.82   \n",
       "E07000064                        Rother  2.19  3.02   0.83   \n",
       "E07000137                  East Lindsey  3.26  4.12   0.86   \n",
       "\n",
       "                          topic        parent  \n",
       "E09000030  care_40PlushoursWeek        London  \n",
       "E09000002  care_40PlushoursWeek        London  \n",
       "E09000001  care_40PlushoursWeek        London  \n",
       "E09000025  care_40PlushoursWeek        London  \n",
       "E09000012  care_40PlushoursWeek        London  \n",
       "...                         ...           ...  \n",
       "E07000146  care_40PlushoursWeek       Norfolk  \n",
       "E07000076  care_40PlushoursWeek         Essex  \n",
       "E06000027  care_40PlushoursWeek    South West  \n",
       "E07000064  care_40PlushoursWeek   East Sussex  \n",
       "E07000137  care_40PlushoursWeek  Lincolnshire  \n",
       "\n",
       "[662 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lad</th>\n",
       "      <th>2001</th>\n",
       "      <th>2011</th>\n",
       "      <th>change</th>\n",
       "      <th>topic</th>\n",
       "      <th>parent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E09000030</th>\n",
       "      <td>Tower Hamlets</td>\n",
       "      <td>2.38</td>\n",
       "      <td>1.93</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>care_40PlushoursWeek</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E09000002</th>\n",
       "      <td>Barking and Dagenham</td>\n",
       "      <td>2.69</td>\n",
       "      <td>2.49</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>care_40PlushoursWeek</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E09000001</th>\n",
       "      <td>City of London</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>care_40PlushoursWeek</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E09000025</th>\n",
       "      <td>Newham</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.05</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>care_40PlushoursWeek</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E09000012</th>\n",
       "      <td>Hackney</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.67</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>care_40PlushoursWeek</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E07000146</th>\n",
       "      <td>King's Lynn and West Norfolk</td>\n",
       "      <td>2.48</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.77</td>\n",
       "      <td>care_40PlushoursWeek</td>\n",
       "      <td>Norfolk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E07000076</th>\n",
       "      <td>Tendring</td>\n",
       "      <td>2.77</td>\n",
       "      <td>3.54</td>\n",
       "      <td>0.77</td>\n",
       "      <td>care_40PlushoursWeek</td>\n",
       "      <td>Essex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E06000027</th>\n",
       "      <td>Torbay</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.82</td>\n",
       "      <td>care_40PlushoursWeek</td>\n",
       "      <td>South West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E07000064</th>\n",
       "      <td>Rother</td>\n",
       "      <td>2.19</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.83</td>\n",
       "      <td>care_40PlushoursWeek</td>\n",
       "      <td>East Sussex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E07000137</th>\n",
       "      <td>East Lindsey</td>\n",
       "      <td>3.26</td>\n",
       "      <td>4.12</td>\n",
       "      <td>0.86</td>\n",
       "      <td>care_40PlushoursWeek</td>\n",
       "      <td>Lincolnshire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>662 rows Ã— 6 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 494
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "source": [
    "df[ ( ( df['topic'].map(lambda x: x == 'care_40PlushoursWeek') ) & ( df['parent'] == 'North East' ) ) ].sort_values(['change'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                            lad  2001  2011 change                 topic  \\\n",
       "E08000021   Newcastle upon Tyne   2.5  2.44  -0.06  care_40PlushoursWeek   \n",
       "E06000002         Middlesbrough  3.05  3.14   0.09  care_40PlushoursWeek   \n",
       "E06000004      Stockton-on-Tees  2.61  2.77   0.16  care_40PlushoursWeek   \n",
       "E08000022        North Tyneside  2.56  2.73   0.17  care_40PlushoursWeek   \n",
       "E06000005            Darlington  2.38  2.61   0.23  care_40PlushoursWeek   \n",
       "E08000037             Gateshead  2.87  3.12   0.25  care_40PlushoursWeek   \n",
       "E06000001            Hartlepool  3.02  3.31   0.29  care_40PlushoursWeek   \n",
       "E06000047         County Durham  2.94  3.29   0.35  care_40PlushoursWeek   \n",
       "E06000003  Redcar and Cleveland  2.97  3.39   0.42  care_40PlushoursWeek   \n",
       "E06000057        Northumberland  2.37   2.8   0.43  care_40PlushoursWeek   \n",
       "E08000023        South Tyneside  2.73  3.24   0.51  care_40PlushoursWeek   \n",
       "E08000024            Sunderland  2.98  3.49   0.51  care_40PlushoursWeek   \n",
       "\n",
       "               parent  \n",
       "E08000021  North East  \n",
       "E06000002  North East  \n",
       "E06000004  North East  \n",
       "E08000022  North East  \n",
       "E06000005  North East  \n",
       "E08000037  North East  \n",
       "E06000001  North East  \n",
       "E06000047  North East  \n",
       "E06000003  North East  \n",
       "E06000057  North East  \n",
       "E08000023  North East  \n",
       "E08000024  North East  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lad</th>\n",
       "      <th>2001</th>\n",
       "      <th>2011</th>\n",
       "      <th>change</th>\n",
       "      <th>topic</th>\n",
       "      <th>parent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E08000021</th>\n",
       "      <td>Newcastle upon Tyne</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.44</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>care_40PlushoursWeek</td>\n",
       "      <td>North East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E06000002</th>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>3.05</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.09</td>\n",
       "      <td>care_40PlushoursWeek</td>\n",
       "      <td>North East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E06000004</th>\n",
       "      <td>Stockton-on-Tees</td>\n",
       "      <td>2.61</td>\n",
       "      <td>2.77</td>\n",
       "      <td>0.16</td>\n",
       "      <td>care_40PlushoursWeek</td>\n",
       "      <td>North East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E08000022</th>\n",
       "      <td>North Tyneside</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0.17</td>\n",
       "      <td>care_40PlushoursWeek</td>\n",
       "      <td>North East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E06000005</th>\n",
       "      <td>Darlington</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.23</td>\n",
       "      <td>care_40PlushoursWeek</td>\n",
       "      <td>North East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E08000037</th>\n",
       "      <td>Gateshead</td>\n",
       "      <td>2.87</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.25</td>\n",
       "      <td>care_40PlushoursWeek</td>\n",
       "      <td>North East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E06000001</th>\n",
       "      <td>Hartlepool</td>\n",
       "      <td>3.02</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.29</td>\n",
       "      <td>care_40PlushoursWeek</td>\n",
       "      <td>North East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E06000047</th>\n",
       "      <td>County Durham</td>\n",
       "      <td>2.94</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.35</td>\n",
       "      <td>care_40PlushoursWeek</td>\n",
       "      <td>North East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E06000003</th>\n",
       "      <td>Redcar and Cleveland</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.42</td>\n",
       "      <td>care_40PlushoursWeek</td>\n",
       "      <td>North East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E06000057</th>\n",
       "      <td>Northumberland</td>\n",
       "      <td>2.37</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.43</td>\n",
       "      <td>care_40PlushoursWeek</td>\n",
       "      <td>North East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E08000023</th>\n",
       "      <td>South Tyneside</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.51</td>\n",
       "      <td>care_40PlushoursWeek</td>\n",
       "      <td>North East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E08000024</th>\n",
       "      <td>Sunderland</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.51</td>\n",
       "      <td>care_40PlushoursWeek</td>\n",
       "      <td>North East</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 495
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "source": [
    "subjectList = [\"NoWelsh\", \"Male31-48\", \"Male16-30\", \"Female31-48\", \"Female16-30\", \"Widowed\", \"65andOver\", \"Other\", \"noCare\", \"Sikh\", \"Religionnotstated\", \"MultiOther\", \"Otherreligion\", \"fair\", \"rent_free\", \"shared_ownership\", \"bicycle\", \"taxi\", \"moto\", \"other\", \"female\", \"male\", \"inactive\", \"mixed\", \"LoneNKids\", \"MultiStudents\", '1to19hoursWeek']\n",
    "topicList = [\"age10yr\"]\n",
    "\n",
    "# Find each LAD local and national ranks and put in prioirity order\n",
    "for thisLad in lads:\n",
    "\n",
    "    try:\n",
    "        thisLad['similar'] = [\n",
    "            {'code': simiDF[simiDF['Code']==thisLad['code']]['Code.1'].iloc[0], 'name': simiDF[simiDF['Code']==thisLad['code']]['Name.1'].iloc[0]},\n",
    "            {'code': simiDF[simiDF['Code']==thisLad['code']]['Code.2'].iloc[0], 'name': simiDF[simiDF['Code']==thisLad['code']]['Name.2'].iloc[0]},\n",
    "            {'code': simiDF[simiDF['Code']==thisLad['code']]['Code.3'].iloc[0], 'name': simiDF[simiDF['Code']==thisLad['code']]['Name.3'].iloc[0]}\n",
    "        ]\n",
    "    except:\n",
    "        thisLad['similar'] = [\n",
    "            {'code': 'faulty pre-process', 'name': 'faulty pre-process'},\n",
    "            {'code': 'faulty pre-process', 'name': 'faulty pre-process'},\n",
    "            {'code': 'faulty pre-process', 'name': 'faulty pre-process'}\n",
    "        ]\n",
    "    \n",
    "    if (areaClassDF[areaClassDF['Code']==thisLad['code']]['Subgroup code'].shape[0]>0):\n",
    "        thisLad['classification'] = areaClassLU[areaClassDF[areaClassDF['Code']==thisLad['code']]['Subgroup code'].iloc[0]]\n",
    "    else:\n",
    "        thisLad['classification'] = \"unk\"\n",
    "    thisLad['gss'] = {}\n",
    "    thisLad['gss']['short'] = gssLookupShort[thisLad['code'][:3]]\n",
    "    thisLad['gss']['long'] = gssLookup[thisLad['code'][:3]]\n",
    "    \n",
    "    if thisLad['parents'][0]['type'] == \"cty\":\n",
    "        thisLad['parents'] = thisLad['parents'][1:]\n",
    "    \n",
    "    # Empty array will be populted with ranks for each variable\n",
    "    ranks = []\n",
    "\n",
    "    # Filter areas with same parent\n",
    "    sister_lads = []\n",
    "    try:\n",
    "        par_name = next(i for i in thisLad['parents'] if ([j for j in i.values()][2] == 'rgn'))['name']\n",
    "    except:\n",
    "        par_name = next(i for i in thisLad['parents'] if ([j for j in i.values()][2] == 'ctry'))['name']\n",
    "        \n",
    "    for thatLad in lads:\n",
    "        try:\n",
    "            if  par_name == next(i for i in thatLad['parents'] if ([j for j in i.values()][2] == 'rgn'))['name']:\n",
    "                sister_lads.append(thatLad)\n",
    "        except:\n",
    "            if par_name=='Wales':\n",
    "                sister_lads.append(thatLad)\n",
    "\n",
    "    # Loop through the various data variables\n",
    "    for a in thisLad['data']:\n",
    "        if a not in topicList:\n",
    "            if a in ['population', 'density', 'agemed']:\n",
    "                b = 'value'\n",
    "            else:\n",
    "                b = 'perc'\n",
    "            # Create nested object with localised rank\n",
    "            thisLad['data'][a][b+\"_rank_local\"] = {}    \n",
    "            for c in ['2001', '2011', 'change']:\n",
    "                thisLad['data'][a][b+\"_rank_local\"][c] = {}\n",
    "                for d in thisLad['data'][a][b][c]:\n",
    "                    if d not in subjectList:\n",
    "                        vari = thisLad['data'][a][b][c][d]\n",
    "\n",
    "                        # Create sorted list of values from sister areas\n",
    "                        group_values = []\n",
    "                        for lad in sister_lads:\n",
    "                            group_values.append(lad['data'][a][b][c][d])\n",
    "                            group_values = [x if (type(x) == float) | (type(x) == int) else np.nan for x in group_values]\n",
    "                        group_values.sort(reverse=True)\n",
    "\n",
    "\n",
    "                        # Find index of value of area of interest\n",
    "                        varRank = group_values.index(vari) + 1\n",
    "\n",
    "                        # Convert bottom half rankings into negative values\n",
    "                        if varRank>len(group_values)/2:\n",
    "                            varRank = varRank-len(group_values)-1\n",
    "\n",
    "                        # Find the variable's rank nationally\n",
    "                        if thisLad['parents'][0]['name'] == \"Wales\":\n",
    "                            natRank = [i for i in df[(df['parent']==\"Wales\")&(df['topic']==a+\"_\"+d)].sort_values(by=[c], ascending=False)['lad']].index(thisLad['name'])+1\n",
    "                            if natRank > noOfLads[\"Wales\"]/2:\n",
    "                                natRank = natRank-noOfLads[\"Wales\"]-1\n",
    "                        else:\n",
    "                            # Index + 1 gives toprank = 1\n",
    "                            natRank = [i for i in df[(df['parent']!=\"Wales\")&(df['topic']==a+\"_\"+d)].sort_values(by=[c], ascending=False)['lad']].index(thisLad['name'])+1\n",
    "                            # If the rank is in the bottom half, ie, greater value than the middle rank\n",
    "                            if natRank > noOfLads[\"England\"]/2:\n",
    "                                natRank = (natRank-noOfLads[\"England\"])-1\n",
    "\n",
    "                        thisLad['data'][a][b+\"_rank_local\"][c][d] = varRank\n",
    "                        thisLad['data'][a][b+\"_rank\"][c][d] = natRank\n",
    "\n",
    "                        # Append ranking data to original array\n",
    "                        ranks.append({\n",
    "                            'label': a+'_'+b+'_'+c+'_'+d, \n",
    "                            'locRank': varRank, \n",
    "                            'natRank': natRank, \n",
    "                            'value': vari})\n",
    "\n",
    "    # Sort in rank order\n",
    "    ranks = sorted(ranks, key=lambda x: (abs(x['locRank']), -abs(x['value'])))\n",
    "    thisLad[\"Priorities\"] = ranks"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "source": [
    "df = pd.DataFrame(columns=\n",
    "                  ['lad', '2001',  '2011',  'change', 'natRank', 'localRank', 'topic', 'parent'])\n",
    "for j in range(len(topics)):\n",
    "    df1 = pd.DataFrame(index=ladCodes, columns=\n",
    "                      ['lad', '2001',  '2011',  'change', 'natRank', 'localRank', 'topic', 'parent'])\n",
    "    for i in range(len(lads)):\n",
    "        df1['lad'].iloc[i] = lads[i]['name']\n",
    "        df1['2001'].iloc[i] = lads[i]['data'][topics[j][1]][topics[j][2]]['2001'][topics[j][3]]\n",
    "        df1['2011'].iloc[i] = lads[i]['data'][topics[j][1]][topics[j][2]]['2011'][topics[j][3]]    \n",
    "        df1['change'].iloc[i] = lads[i]['data'][topics[j][1]][topics[j][2]]['change'][topics[j][3]]\n",
    "        df1['natRank'].iloc[i] = lads[i]['data'][topics[j][1]][topics[j][2]+\"_rank\"]['change'][topics[j][3]]    \n",
    "        df1['localRank'].iloc[i] = lads[i]['data'][topics[j][1]][topics[j][2]+\"_rank_local\"]['change'][topics[j][3]]    \n",
    "        df1['topic'].iloc[i] = topics[j][1]+\"_\"+topics[j][3]\n",
    "        try:\n",
    "            df1['parent'].iloc[i] = next(k for k in lads[i]['parents'] if ([j for j in k.values()][2] == 'rgn'))['name']\n",
    "        except:\n",
    "            df1['parent'].iloc[i] = next(k for k in lads[i]['parents'] if ([j for j in k.values()][2] == 'ctry'))['name']\n",
    "\n",
    "    df = pd.concat([df,df1])\n",
    "\n",
    "for topic in topics:\n",
    "    for lad in lads:\n",
    "        \n",
    "        # Find the areas that this area has overtaken\n",
    "        v2001 = lad['data'][topic[1]][topic[2]]['2001'][topic[3]]\n",
    "        v2011 = lad['data'][topic[1]][topic[2]]['2011'][topic[3]]\n",
    "        if thisLad['parents'][0]['name'] == \"Wales\":\n",
    "            dfT = df[(df['parent']==\"Wales\")&(df['topic']==topic[1]+\"_\"+topic[3])&(df['2001']>v2001)&(df['2011']<v2011)]\n",
    "        else:\n",
    "            dfT = df[(df['parent']!=\"Wales\")&(df['topic']==topic[1]+\"_\"+topic[3])&(df['2001']>v2001)&(df['2011']<v2011)]\n",
    "\n",
    "        obje = []\n",
    "        for i in range(dfT.shape[0]):\n",
    "            obje.append(dfT.iloc[i]['lad'])\n",
    "        \n",
    "        if 'overtake' not in lad['data'][topic[1]][topic[2]+'_rank'].keys():\n",
    "            lad['data'][topic[1]][topic[2]+'_rank']['overtake'] = {}\n",
    "        lad['data'][topic[1]][topic[2]+\"_rank\"]['overtake'][topic[3]] = obje\n",
    "\n",
    "\n",
    "        # Find areas within the region that this area has overtaken\n",
    "        reg = lad['parents'][0]['name']\n",
    "        dfTr = df[(df['topic']==topic[1]+\"_\"+topic[3])&(df['2001']>v2001)&(df['2011']<v2011)&(df['parent']==reg)]\n",
    "        objeR = []\n",
    "        for i in range(dfTr.shape[0]):\n",
    "            objeR.append(dfTr.iloc[i]['lad'])\n",
    "        if 'overtake' not in lad['data'][topic[1]][topic[2]+'_rank_local'].keys():\n",
    "            lad['data'][topic[1]][topic[2]+'_rank_local']['overtake'] = {}\n",
    "        lad['data'][topic[1]][topic[2]+\"_rank_local\"]['overtake'][topic[3]] = objeR\n",
    "        \n",
    "        dfReg = df[(df['topic']==topic[1]+\"_\"+topic[3])&(df['parent']==reg)]\n",
    "        rank2001 = sorted(dfReg['2001'], reverse=True).index(v2001)+1\n",
    "        if rank2001 > 168:\n",
    "            rank2001 = rank2001-336-1\n",
    "        if '2001' not in lad['data'][topic[1]][topic[2]+'_rank_local'].keys():\n",
    "            lad['data'][topic[1]][topic[2]+'_rank_local']['2001'] = {}\n",
    "        lad['data'][topic[1]][topic[2]+'_rank_local']['2001'][topic[3]] = rank2001\n",
    "\n",
    "\n",
    "        # Find the area immediatly above or below\n",
    "        above = lad['data'][topic[1]][topic[2]+'_rank_local']['2011'][topic[3]]-2\n",
    "        below = lad['data'][topic[1]][topic[2]+'_rank_local']['2011'][topic[3]]\n",
    "        if below<0:\n",
    "            above = lad['data'][topic[1]][topic[2]+'_rank_local']['2011'][topic[3]]-1\n",
    "            below = lad['data'][topic[1]][topic[2]+'_rank_local']['2011'][topic[3]]+1\n",
    "            \n",
    "        name_above = df[(df['parent']==reg)&(df['topic']==topic[1]+\"_\"+topic[3])].sort_values('2011', ascending=False).iloc[above]['lad']\n",
    "        name_below = df[(df['parent']==reg)&(df['topic']==topic[1]+\"_\"+topic[3])].sort_values('2011', ascending=False).iloc[below]['lad']\n",
    "\n",
    "        area_above = {'name': name_above,\n",
    "                         'value': df[(df['lad']==name_above)&(df['topic']==topic[1]+\"_\"+topic[3])]['2011'].iloc[0]}\n",
    "        area_below = {'name': name_below,\n",
    "                          'value': df[(df['lad']==name_below)&(df['topic']==topic[1]+\"_\"+topic[3])]['2011'].iloc[0]}\n",
    "\n",
    "\n",
    "        if 'above_below' not in lad['data'][topic[1]][topic[2]+'_rank_local'].keys():\n",
    "            lad['data'][topic[1]][topic[2]+'_rank_local']['above_below'] = {}\n",
    "\n",
    "        if topic[3] not in lad['data'][topic[1]][topic[2]+'_rank_local']['above_below'].keys():\n",
    "            lad['data'][topic[1]][topic[2]+'_rank_local']['above_below'][topic[3]] = {}\n",
    "        \n",
    "        lad['data'][topic[1]][topic[2]+'_rank_local']['above_below'][topic[3]][\"above\"] = area_above\n",
    "        lad['data'][topic[1]][topic[2]+'_rank_local']['above_below'][topic[3]][\"below\"] = area_below\n",
    "            \n",
    "        # Add top and bottom three biggest movers for each subject to every area\n",
    "        if thisLad['parents'][0]['name'] == \"Wales\":\n",
    "            df_topic = df[(df['parent']==\"Wales\")&(df['topic']==topic[1]+\"_\"+topic[3])&(abs(df['natRank'])<4)]\n",
    "        else:\n",
    "            df_topic = df[(df['parent']!=\"Wales\")&(df['topic']==topic[1]+\"_\"+topic[3])&(abs(df['natRank'])<4)]\n",
    "\n",
    "        ob = {}\n",
    "        for index, row in df_topic.iterrows():\n",
    "            ob[int(row['natRank'])] = {'name': row['lad'], 2001: row['2001'], 2011: row['2011'], 'change': row['change']}\n",
    "        if 'top_bottom' not in lad['data'][topic[1]][topic[2]+'_rank'].keys():\n",
    "            lad['data'][topic[1]][topic[2]+'_rank']['top_bottom'] = {}\n",
    "        lad['data'][topic[1]][topic[2]+'_rank']['top_bottom'][topic[3]]=ob\n",
    "        \n",
    "        \n",
    "        # Add top and bottom three biggest movers for each subject to every area (regional)\n",
    "        df_topicReg = df[(df['topic']==topic[1]+\"_\"+topic[3])&(abs(df['localRank'])<4)&(df['parent']==reg)]\n",
    "\n",
    "        ob = {}\n",
    "        for index, row in df_topicReg.iterrows():\n",
    "            if int(row['localRank']) in ob.keys():\n",
    "                if int(row['localRank']) > 0:\n",
    "                    ob[int(row['localRank'])+1] = {'name': row['lad'], 2001: row['2001'], 2011: row['2011'], 'change': row['change']}\n",
    "                else:\n",
    "                    ob[int(row['localRank'])+1] = {'name': row['lad'], 2001: row['2001'], 2011: row['2011'], 'change': row['change']}\n",
    "            else:\n",
    "                ob[int(row['localRank'])] = {'name': row['lad'], 2001: row['2001'], 2011: row['2011'], 'change': row['change']}\n",
    "        if 'top_bottom' not in lad['data'][topic[1]][topic[2]+'_rank_local'].keys():\n",
    "            lad['data'][topic[1]][topic[2]+'_rank_local']['top_bottom'] = {}\n",
    "        lad['data'][topic[1]][topic[2]+'_rank_local']['top_bottom'][topic[3]]=ob"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "source": [
    "this(\"Copeland\")['Priorities']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'label': 'tenure_perc_2011_rented_private',\n",
       "  'locRank': -1,\n",
       "  'natRank': -4,\n",
       "  'value': 8.73},\n",
       " {'label': 'agemed_value_change_all',\n",
       "  'locRank': 1,\n",
       "  'natRank': 3,\n",
       "  'value': 5.0},\n",
       " {'label': 'tenure_perc_change_owned',\n",
       "  'locRank': 1,\n",
       "  'natRank': 1,\n",
       "  'value': 3.39},\n",
       " {'label': 'hoursworked_perc_2011_Male1-15',\n",
       "  'locRank': -1,\n",
       "  'natRank': -2,\n",
       "  'value': 2.12},\n",
       " {'label': 'tenure_perc_change_rented_private',\n",
       "  'locRank': -1,\n",
       "  'natRank': -2,\n",
       "  'value': 2.04},\n",
       " {'label': 'economic_perc_2011_student',\n",
       "  'locRank': -1,\n",
       "  'natRank': -2,\n",
       "  'value': 1.74},\n",
       " {'label': 'economic_perc_2001_student',\n",
       "  'locRank': -1,\n",
       "  'natRank': -2,\n",
       "  'value': 1.39},\n",
       " {'label': 'welsh_perc_2001_SpeaksWelsh',\n",
       "  'locRank': 1,\n",
       "  'natRank': -54,\n",
       "  'value': 1},\n",
       " {'label': 'welsh_perc_2001_all', 'locRank': 1, 'natRank': -54, 'value': 1},\n",
       " {'label': 'welsh_perc_2011_SpeaksWelsh',\n",
       "  'locRank': 1,\n",
       "  'natRank': -54,\n",
       "  'value': 1},\n",
       " {'label': 'welsh_perc_2011_all', 'locRank': 1, 'natRank': -54, 'value': 1},\n",
       " {'label': 'welsh_perc_change_SpeaksWelsh',\n",
       "  'locRank': 1,\n",
       "  'natRank': -54,\n",
       "  'value': 1},\n",
       " {'label': 'welsh_perc_change_all', 'locRank': 1, 'natRank': -54, 'value': 1},\n",
       " {'label': 'economic_perc_change_unemployed',\n",
       "  'locRank': -1,\n",
       "  'natRank': -1,\n",
       "  'value': -0.78},\n",
       " {'label': 'hoursworked_perc_change_Male1-15',\n",
       "  'locRank': -1,\n",
       "  'natRank': -21,\n",
       "  'value': 0.76},\n",
       " {'label': 'religion_perc_2001_Jewish',\n",
       "  'locRank': -1,\n",
       "  'natRank': -5,\n",
       "  'value': 0.02},\n",
       " {'label': 'religion_perc_2011_Christian',\n",
       "  'locRank': 2,\n",
       "  'natRank': 2,\n",
       "  'value': 78.87},\n",
       " {'label': 'hoursworked_perc_change_Male49plus',\n",
       "  'locRank': 2,\n",
       "  'natRank': 16,\n",
       "  'value': -1.69},\n",
       " {'label': 'hoursworked_perc_change_Female1-15',\n",
       "  'locRank': -2,\n",
       "  'natRank': -3,\n",
       "  'value': -1.22},\n",
       " {'label': 'household_perc_change_LoneParent',\n",
       "  'locRank': -2,\n",
       "  'natRank': -4,\n",
       "  'value': -0.84},\n",
       " {'label': 'ethnicity_perc_2001_white',\n",
       "  'locRank': 3,\n",
       "  'natRank': 6,\n",
       "  'value': 99.3},\n",
       " {'label': 'ethnicity_perc_2011_white',\n",
       "  'locRank': 3,\n",
       "  'natRank': 15,\n",
       "  'value': 98.42},\n",
       " {'label': 'religion_perc_2001_Christian',\n",
       "  'locRank': 3,\n",
       "  'natRank': 3,\n",
       "  'value': 86.31},\n",
       " {'label': 'travel_perc_2001_car_van',\n",
       "  'locRank': 3,\n",
       "  'natRank': 21,\n",
       "  'value': 72.23},\n",
       " {'label': 'religion_perc_2011_Noreligion',\n",
       "  'locRank': -3,\n",
       "  'natRank': -8,\n",
       "  'value': 14.37},\n",
       " {'label': 'religion_perc_change_Christian',\n",
       "  'locRank': 3,\n",
       "  'natRank': 10,\n",
       "  'value': -7.44},\n",
       " {'label': 'economic_perc_2001_unemployed',\n",
       "  'locRank': 3,\n",
       "  'natRank': 23,\n",
       "  'value': 5.02},\n",
       " {'label': 'tenure_perc_change_rented_social',\n",
       "  'locRank': -3,\n",
       "  'natRank': -19,\n",
       "  'value': -4.41},\n",
       " {'label': 'economic_perc_change_employee',\n",
       "  'locRank': 3,\n",
       "  'natRank': 5,\n",
       "  'value': 4.03},\n",
       " {'label': 'population_value_2001_all',\n",
       "  'locRank': -4,\n",
       "  'natRank': -21,\n",
       "  'value': 69318.0},\n",
       " {'label': 'hoursworked_perc_2001_Male49plus',\n",
       "  'locRank': -4,\n",
       "  'natRank': -5,\n",
       "  'value': 8.9},\n",
       " {'label': 'religion_perc_2001_Noreligion',\n",
       "  'locRank': -4,\n",
       "  'natRank': -4,\n",
       "  'value': 7.0},\n",
       " {'label': 'marital_perc_change_Married',\n",
       "  'locRank': 4,\n",
       "  'natRank': 62,\n",
       "  'value': -2.9},\n",
       " {'label': 'household_perc_change_Married',\n",
       "  'locRank': 4,\n",
       "  'natRank': 76,\n",
       "  'value': -2.62},\n",
       " {'label': 'density_value_2011_all',\n",
       "  'locRank': -4,\n",
       "  'natRank': -20,\n",
       "  'value': 0.96},\n",
       " {'label': 'economic_perc_change_student',\n",
       "  'locRank': -4,\n",
       "  'natRank': -63,\n",
       "  'value': 0.35},\n",
       " {'label': 'ethnicity_perc_2001_asian',\n",
       "  'locRank': -4,\n",
       "  'natRank': -17,\n",
       "  'value': 0.31},\n",
       " {'label': 'ethnicity_perc_2001_black',\n",
       "  'locRank': -4,\n",
       "  'natRank': -9,\n",
       "  'value': 0.06},\n",
       " {'label': 'travel_perc_change_train_metro',\n",
       "  'locRank': -4,\n",
       "  'natRank': -16,\n",
       "  'value': -0.05},\n",
       " {'label': 'population_value_2011_all',\n",
       "  'locRank': -5,\n",
       "  'natRank': -19,\n",
       "  'value': 70603.0},\n",
       " {'label': 'religion_perc_change_Noreligion',\n",
       "  'locRank': -5,\n",
       "  'natRank': -35,\n",
       "  'value': 7.37},\n",
       " {'label': 'health_perc_change_bad',\n",
       "  'locRank': 5,\n",
       "  'natRank': -123,\n",
       "  'value': -3.5},\n",
       " {'label': 'marital_perc_change_Single',\n",
       "  'locRank': -5,\n",
       "  'natRank': -87,\n",
       "  'value': 3.09},\n",
       " {'label': 'household_perc_change_Cohabiting',\n",
       "  'locRank': 5,\n",
       "  'natRank': 21,\n",
       "  'value': 2.52},\n",
       " {'label': 'hoursworked_perc_2001_Male1-15',\n",
       "  'locRank': -5,\n",
       "  'natRank': -19,\n",
       "  'value': 1.36},\n",
       " {'label': 'density_value_2001_all',\n",
       "  'locRank': -5,\n",
       "  'natRank': -24,\n",
       "  'value': 0.95},\n",
       " {'label': 'economic_perc_change_self-employed',\n",
       "  'locRank': -5,\n",
       "  'natRank': -18,\n",
       "  'value': 0.57},\n",
       " {'label': 'ethnicity_perc_2011_black',\n",
       "  'locRank': -5,\n",
       "  'natRank': -13,\n",
       "  'value': 0.12},\n",
       " {'label': 'agemed_value_2011_all',\n",
       "  'locRank': 6,\n",
       "  'natRank': 59,\n",
       "  'value': 44.0},\n",
       " {'label': 'hoursworked_perc_2001_Female1-15',\n",
       "  'locRank': 6,\n",
       "  'natRank': 79,\n",
       "  'value': 7.4},\n",
       " {'label': 'ethnicity_perc_2011_asian',\n",
       "  'locRank': -6,\n",
       "  'natRank': -42,\n",
       "  'value': 0.89},\n",
       " {'label': 'household_perc_change_OnePerson',\n",
       "  'locRank': -6,\n",
       "  'natRank': -120,\n",
       "  'value': 0.43},\n",
       " {'label': 'religion_perc_2011_Hindu',\n",
       "  'locRank': -6,\n",
       "  'natRank': -39,\n",
       "  'value': 0.11},\n",
       " {'label': 'travel_perc_2011_car_van',\n",
       "  'locRank': 7,\n",
       "  'natRank': 40,\n",
       "  'value': 75.5},\n",
       " {'label': 'tenure_perc_2001_owned',\n",
       "  'locRank': -7,\n",
       "  'natRank': -73,\n",
       "  'value': 67.58},\n",
       " {'label': 'marital_perc_2011_Seperated',\n",
       "  'locRank': -7,\n",
       "  'natRank': -94,\n",
       "  'value': 11.11},\n",
       " {'label': 'travel_perc_2001_foot',\n",
       "  'locRank': -7,\n",
       "  'natRank': -83,\n",
       "  'value': 8.93},\n",
       " {'label': 'children_perc_change_Kids',\n",
       "  'locRank': -7,\n",
       "  'natRank': -17,\n",
       "  'value': -2.76},\n",
       " {'label': 'hoursworked_perc_2011_Female49plus',\n",
       "  'locRank': -7,\n",
       "  'natRank': -20,\n",
       "  'value': 2.06},\n",
       " {'label': 'hoursworked_perc_change_Female49plus',\n",
       "  'locRank': -7,\n",
       "  'natRank': -25,\n",
       "  'value': -0.34},\n",
       " {'label': 'religion_perc_2001_Hindu',\n",
       "  'locRank': -7,\n",
       "  'natRank': -30,\n",
       "  'value': 0.06},\n",
       " {'label': 'marital_perc_2011_Married',\n",
       "  'locRank': 8,\n",
       "  'natRank': 121,\n",
       "  'value': 51.21},\n",
       " {'label': 'household_perc_2011_Married',\n",
       "  'locRank': 8,\n",
       "  'natRank': 113,\n",
       "  'value': 36.62},\n",
       " {'label': 'tenure_perc_2001_rented_social',\n",
       "  'locRank': 8,\n",
       "  'natRank': 56,\n",
       "  'value': 22.97},\n",
       " {'label': 'household_perc_2011_LoneParent',\n",
       "  'locRank': -8,\n",
       "  'natRank': -143,\n",
       "  'value': 9.39},\n",
       " {'label': 'household_perc_2001_Cohabiting',\n",
       "  'locRank': -8,\n",
       "  'natRank': -22,\n",
       "  'value': 6.92},\n",
       " {'label': 'religion_perc_2001_Muslim',\n",
       "  'locRank': -8,\n",
       "  'natRank': -50,\n",
       "  'value': 0.18},\n",
       " {'label': 'religion_perc_2011_Jewish',\n",
       "  'locRank': -8,\n",
       "  'natRank': -11,\n",
       "  'value': 0.02},\n",
       " {'label': 'marital_perc_2011_Single',\n",
       "  'locRank': -9,\n",
       "  'natRank': -124,\n",
       "  'value': 29.71},\n",
       " {'label': 'health_perc_change_good',\n",
       "  'locRank': -9,\n",
       "  'natRank': -62,\n",
       "  'value': 11.55},\n",
       " {'label': 'hoursworked_perc_2011_Male49plus',\n",
       "  'locRank': -9,\n",
       "  'natRank': -16,\n",
       "  'value': 7.21},\n",
       " {'label': 'economic_perc_2011_self-employed',\n",
       "  'locRank': -9,\n",
       "  'natRank': -34,\n",
       "  'value': 6.97},\n",
       " {'label': 'travel_perc_2001_train_metro',\n",
       "  'locRank': 9,\n",
       "  'natRank': 123,\n",
       "  'value': 1.72},\n",
       " {'label': 'travel_perc_change_bus',\n",
       "  'locRank': -9,\n",
       "  'natRank': -50,\n",
       "  'value': -1.32},\n",
       " {'label': 'ethnicity_perc_change_white',\n",
       "  'locRank': 9,\n",
       "  'natRank': 42,\n",
       "  'value': -0.88},\n",
       " {'label': 'religion_perc_2011_Muslim',\n",
       "  'locRank': -9,\n",
       "  'natRank': -61,\n",
       "  'value': 0.32},\n",
       " {'label': 'religion_perc_2001_Buddhist',\n",
       "  'locRank': -9,\n",
       "  'natRank': -33,\n",
       "  'value': 0.1},\n",
       " {'label': 'economic_perc_2011_employee',\n",
       "  'locRank': 10,\n",
       "  'natRank': 126,\n",
       "  'value': 54.09},\n",
       " {'label': 'children_perc_2011_Kids',\n",
       "  'locRank': -10,\n",
       "  'natRank': -79,\n",
       "  'value': 26.58},\n",
       " {'label': 'marital_perc_2001_Seperated',\n",
       "  'locRank': -10,\n",
       "  'natRank': -129,\n",
       "  'value': 10.25},\n",
       " {'label': 'travel_perc_change_foot',\n",
       "  'locRank': 10,\n",
       "  'natRank': 74,\n",
       "  'value': 1.41},\n",
       " {'label': 'care_perc_change_40PlushoursWeek',\n",
       "  'locRank': 10,\n",
       "  'natRank': 61,\n",
       "  'value': 0.53},\n",
       " {'label': 'religion_perc_change_Muslim',\n",
       "  'locRank': -10,\n",
       "  'natRank': -73,\n",
       "  'value': 0.14},\n",
       " {'label': 'density_value_change_all',\n",
       "  'locRank': -10,\n",
       "  'natRank': -17,\n",
       "  'value': 0.010000000000000009},\n",
       " {'label': 'children_perc_2011_NonDepKids',\n",
       "  'locRank': 11,\n",
       "  'natRank': 46,\n",
       "  'value': 10.89},\n",
       " {'label': 'travel_perc_2011_bus',\n",
       "  'locRank': -11,\n",
       "  'natRank': 153,\n",
       "  'value': 4.74},\n",
       " {'label': 'population_value_change_all',\n",
       "  'locRank': -11,\n",
       "  'natRank': -29,\n",
       "  'value': 1.85},\n",
       " {'label': 'care_perc_2001_20to49hoursWeek',\n",
       "  'locRank': 11,\n",
       "  'natRank': 35,\n",
       "  'value': 1.37},\n",
       " {'label': 'ethnicity_perc_change_black',\n",
       "  'locRank': -11,\n",
       "  'natRank': -36,\n",
       "  'value': 0.06},\n",
       " {'label': 'tenure_perc_2011_owned',\n",
       "  'locRank': 12,\n",
       "  'natRank': 103,\n",
       "  'value': 70.97},\n",
       " {'label': 'household_perc_2001_Married',\n",
       "  'locRank': 12,\n",
       "  'natRank': 154,\n",
       "  'value': 39.24},\n",
       " {'label': 'agemed_value_2001_all',\n",
       "  'locRank': 12,\n",
       "  'natRank': 132,\n",
       "  'value': 39.0},\n",
       " {'label': 'children_perc_2001_Kids',\n",
       "  'locRank': -12,\n",
       "  'natRank': -138,\n",
       "  'value': 29.34},\n",
       " {'label': 'economic_perc_2001_self-employed',\n",
       "  'locRank': -12,\n",
       "  'natRank': -61,\n",
       "  'value': 6.4},\n",
       " {'label': 'children_perc_change_NoKids',\n",
       "  'locRank': 12,\n",
       "  'natRank': 34,\n",
       "  'value': 2.35},\n",
       " {'label': 'marital_perc_change_Seperated',\n",
       "  'locRank': -12,\n",
       "  'natRank': -77,\n",
       "  'value': 0.86},\n",
       " {'label': 'children_perc_2011_NoKids',\n",
       "  'locRank': 13,\n",
       "  'natRank': 125,\n",
       "  'value': 62.53},\n",
       " {'label': 'marital_perc_2001_Married',\n",
       "  'locRank': 13,\n",
       "  'natRank': -154,\n",
       "  'value': 54.11},\n",
       " {'label': 'marital_perc_2001_Single',\n",
       "  'locRank': -13,\n",
       "  'natRank': -152,\n",
       "  'value': 26.62},\n",
       " {'label': 'travel_perc_2001_home',\n",
       "  'locRank': -13,\n",
       "  'natRank': -80,\n",
       "  'value': 8.23},\n",
       " {'label': 'hoursworked_perc_2001_Female49plus',\n",
       "  'locRank': -13,\n",
       "  'natRank': -58,\n",
       "  'value': 2.4},\n",
       " {'label': 'care_perc_2011_20to49hoursWeek',\n",
       "  'locRank': 13,\n",
       "  'natRank': 38,\n",
       "  'value': 1.67},\n",
       " {'label': 'religion_perc_change_Buddhist',\n",
       "  'locRank': 13,\n",
       "  'natRank': -135,\n",
       "  'value': 0.11},\n",
       " {'label': 'children_perc_2001_NoKids',\n",
       "  'locRank': 14,\n",
       "  'natRank': -135,\n",
       "  'value': 60.18},\n",
       " {'label': 'tenure_perc_2011_rented_social',\n",
       "  'locRank': 14,\n",
       "  'natRank': 81,\n",
       "  'value': 18.56},\n",
       " {'label': 'household_perc_2011_Cohabiting',\n",
       "  'locRank': -14,\n",
       "  'natRank': -104,\n",
       "  'value': 9.44},\n",
       " {'label': 'care_perc_2011_40PlushoursWeek',\n",
       "  'locRank': 14,\n",
       "  'natRank': 47,\n",
       "  'value': 2.98},\n",
       " {'label': 'children_perc_change_NonDepKids',\n",
       "  'locRank': 14,\n",
       "  'natRank': 108,\n",
       "  'value': 0.41},\n",
       " {'label': 'religion_perc_change_Jewish',\n",
       "  'locRank': 14,\n",
       "  'natRank': 105,\n",
       "  'value': 0.0},\n",
       " {'label': 'economic_perc_2001_employee',\n",
       "  'locRank': -15,\n",
       "  'natRank': -75,\n",
       "  'value': 50.06},\n",
       " {'label': 'children_perc_2001_NonDepKids',\n",
       "  'locRank': 15,\n",
       "  'natRank': 60,\n",
       "  'value': 10.48},\n",
       " {'label': 'tenure_perc_2001_rented_private',\n",
       "  'locRank': -15,\n",
       "  'natRank': -77,\n",
       "  'value': 6.69},\n",
       " {'label': 'travel_perc_2001_bus',\n",
       "  'locRank': -15,\n",
       "  'natRank': 121,\n",
       "  'value': 6.06},\n",
       " {'label': 'travel_perc_change_home',\n",
       "  'locRank': 15,\n",
       "  'natRank': 120,\n",
       "  'value': -4.16},\n",
       " {'label': 'care_perc_2001_40PlushoursWeek',\n",
       "  'locRank': 15,\n",
       "  'natRank': 55,\n",
       "  'value': 2.45},\n",
       " {'label': 'religion_perc_2011_Buddhist',\n",
       "  'locRank': -15,\n",
       "  'natRank': -70,\n",
       "  'value': 0.21},\n",
       " {'label': 'religion_perc_change_Hindu',\n",
       "  'locRank': -15,\n",
       "  'natRank': -65,\n",
       "  'value': 0.05},\n",
       " {'label': 'health_perc_2011_good',\n",
       "  'locRank': -16,\n",
       "  'natRank': -54,\n",
       "  'value': 78.28},\n",
       " {'label': 'household_perc_2011_OnePerson',\n",
       "  'locRank': -16,\n",
       "  'natRank': 104,\n",
       "  'value': 30.48},\n",
       " {'label': 'household_perc_2001_OnePerson',\n",
       "  'locRank': 16,\n",
       "  'natRank': 101,\n",
       "  'value': 30.05},\n",
       " {'label': 'hoursworked_perc_2011_Female1-15',\n",
       "  'locRank': 16,\n",
       "  'natRank': -92,\n",
       "  'value': 6.18},\n",
       " {'label': 'travel_perc_change_car_van',\n",
       "  'locRank': -16,\n",
       "  'natRank': 140,\n",
       "  'value': 3.27},\n",
       " {'label': 'travel_perc_2011_train_metro',\n",
       "  'locRank': -16,\n",
       "  'natRank': -92,\n",
       "  'value': 1.67},\n",
       " {'label': 'health_perc_2001_bad',\n",
       "  'locRank': -17,\n",
       "  'natRank': 63,\n",
       "  'value': 10.33},\n",
       " {'label': 'ethnicity_perc_change_asian',\n",
       "  'locRank': -17,\n",
       "  'natRank': -83,\n",
       "  'value': 0.58},\n",
       " {'label': 'economic_perc_2011_unemployed',\n",
       "  'locRank': -18,\n",
       "  'natRank': 126,\n",
       "  'value': 4.24},\n",
       " {'label': 'health_perc_2001_good',\n",
       "  'locRank': -19,\n",
       "  'natRank': -79,\n",
       "  'value': 66.73},\n",
       " {'label': 'travel_perc_2011_foot',\n",
       "  'locRank': 19,\n",
       "  'natRank': 136,\n",
       "  'value': 10.34},\n",
       " {'label': 'household_perc_2001_LoneParent',\n",
       "  'locRank': -19,\n",
       "  'natRank': 74,\n",
       "  'value': 10.23},\n",
       " {'label': 'travel_perc_2011_home',\n",
       "  'locRank': 19,\n",
       "  'natRank': -90,\n",
       "  'value': 4.07},\n",
       " {'label': 'health_perc_2011_bad',\n",
       "  'locRank': -20,\n",
       "  'natRank': 48,\n",
       "  'value': 6.83},\n",
       " {'label': 'care_perc_change_20to49hoursWeek',\n",
       "  'locRank': -20,\n",
       "  'natRank': 135,\n",
       "  'value': 0.3}]"
      ]
     },
     "metadata": {},
     "execution_count": 498
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "source": [
    "lads_copy = lads.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "source": [
    "lads = lads_copy.copy()\n",
    "# Filter out priority list by subject\n",
    "for lad in lads:\n",
    "    subjectList = [\"Male31-48\", \"Male16-30\", \"Female31-48\", \"Female16-30\", \"Widowed\", \"65andOver\", \"Other\", \"noCare\", \"Sikh\", \"Religionnotstated\", \"MultiOther\", \"Otherreligion\", \"fair\", \"rent_free\", \"shared_ownership\", \"bicycle\", \"taxi\", \"moto\", \"other\", \"female\", \"male\", \"inactive\", \"mixed\", \"LoneNKids\", \"MultiStudents\"]\n",
    "    priorities = []\n",
    "    priorities2011 = []\n",
    "    for rank in lad['Priorities']:\n",
    "        s=rank['label'].split(\"_\")\n",
    "        if len(s)>4:\n",
    "            s[3] = s[3] + \"_\" + s[4]\n",
    "        if ((s[2] == \"change\") & (s[3] not in subjectList) & (((s[0]==\"household\")&(s[3]==\"Married\")) is False)):\n",
    "            if (s[0]=='welsh') & (lad['parents'][0]['name'] != 'Wales'):\n",
    "                pass\n",
    "            else:\n",
    "                rank['2011']=[i for i in this(\"Manchester\")['Priorities'] if i['label']==s[0]+'_'+s[1]+'_2011_'+s[3]][0]['value']\n",
    "                priorities.append(rank)\n",
    "        if (s[2]!=\"change\"):\n",
    "            priorities2011.append(rank)\n",
    "    lad['pri'] = priorities\n",
    "    lad['pri2011'] = priorities2011\n",
    "\n",
    "\n",
    "# Create triple data for areas of closest proximity\n",
    "geogTriples = []\n",
    "for lad in lads:\n",
    "    list1 = lad['bounds'][0]+lad['bounds'][1]\n",
    "    for lad2 in lads:\n",
    "        list2 = lad2['bounds'][0]+lad2['bounds'][1]\n",
    "        listDif = [abs(list1[i]-list2[i]) for i in [0,1,2,3]]\n",
    "        listDif.sort()\n",
    "        if (sum(listDif[:3]) < 1) & (lad!=lad2):\n",
    "            geogTriples.append([lad['name'], lad2['name'], (\"near\", round(sum(listDif[:3]), 2))])\n",
    "\n",
    "\n",
    "sign = lambda x: math.copysign(1, x)\n",
    "\n",
    "for thisLad in lads:\n",
    "    # thisLad['similar'] = thisLad['similarC']\n",
    "\n",
    "    # Find nearby area\n",
    "    nearbyArea = [i for i in geogTriples if i[0]==thisLad['name']]\n",
    "    nearbyArea = [i for i in nearbyArea if this(i[1])['parents'][1]['name'] == thisLad['parents'][1]['name']]\n",
    "\n",
    "    nearbyArea = sorted(nearbyArea, key=lambda x: x[2][1])\n",
    "\n",
    "    #Find differences in data\n",
    "    if (thisLad['parents'][0]['name']=='Wales'):                     \n",
    "        region=[i for i in countries if i['name']==\"Wales\"][0]\n",
    "        country=[i for i in countries if i['name']==\"Wales\"][0]\n",
    "    else:\n",
    "        region=[i for i in regions if i['name']==thisLad['parents'][0]['name']][0]\n",
    "        country=[i for i in countries if i['name']==thisLad['parents'][1]['name']][0]\n",
    "\n",
    "    def reg(i):\n",
    "        s=i['label'].split(\"_\")\n",
    "        if len(s)>4:\n",
    "            s[3] = s[3] + \"_\" + s[4]    \n",
    "        try:\n",
    "            return region['data'][s[0]][s[1]][s[2]][s[3]]\n",
    "        except:\n",
    "            if (thisLad['parents'][0]['name']=='Wales'):\n",
    "                return country['data'][s[0]][s[1]][s[2]][s[3]]\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "    \n",
    "    regDiff = [(i, {'val': reg(i), 'dif': i['value']-reg(i)}) for i in thisLad['pri']]\n",
    "    regDiff = sorted(regDiff, reverse=True, key=lambda x: abs(x[1]['dif']))\n",
    "\n",
    "    def cou(i):\n",
    "        s=i['label'].split(\"_\")\n",
    "        if len(s)>4:\n",
    "            s[3] = s[3] + \"_\" + s[4]\n",
    "        return country['data'][s[0]][s[1]][s[2]][s[3]]\n",
    "    couDiff = [(i, {'val': cou(i), 'dif': i['value']-cou(i)}) for i in thisLad['pri']]\n",
    "    couDiff = sorted(couDiff, reverse=True, key=lambda x: abs(x[1]['dif']))\n",
    "    \n",
    "    try:\n",
    "        nearbyAreaData = {}\n",
    "        nearbyAreaData['name'] = nearbyArea[0][1]\n",
    "        nearbyAreaData['data'] = [lad for lad in lads if lad['name']==nearbyArea[0][1]][0]['data']\n",
    "    except:\n",
    "        print(\"Nearby data not found for:: \", thisLad['name'])\n",
    "        nearbyAreaData = []\n",
    "        \n",
    "    try:\n",
    "        similarData = {}\n",
    "        if (nearbyArea[0][1]!=thisLad['similar'][0]['name']):\n",
    "            try:\n",
    "                similarData['name'] = thisLad['similar'][0]['name']\n",
    "                similarData['data'] = [lad for lad in lads if lad['name']==thisLad['similar'][0]['name']][0]['data']\n",
    "            except:\n",
    "                try:\n",
    "                    similarData['name'] = thisLad['similar'][1]['name']\n",
    "                    similarData['data'] = [lad for lad in lads if lad['name']==thisLad['similar'][1]['name']][0]['data']\n",
    "                except:\n",
    "                    similarData['name'] = thisLad['similar'][2]['name']\n",
    "                    similarData['data'] = [lad for lad in lads if lad['name']==thisLad['similar'][2]['name']][0]['data']\n",
    "        else:\n",
    "            try:\n",
    "                similarData['name'] = thisLad['similar'][1]['name']\n",
    "                similarData['data'] = [lad for lad in lads if lad['name']==thisLad['similar'][1]['name']][0]['data']\n",
    "            except:\n",
    "                similarData['name'] = thisLad['similar'][2]['name']\n",
    "                similarData['data'] = [lad for lad in lads if lad['name']==thisLad['similar'][2]['name']][0]['data']\n",
    "\n",
    "    except:\n",
    "        print(\"Similar data not found for:: \", thisLad['name'])\n",
    "        similarData = []\n",
    "\n",
    "    def simi(i):\n",
    "        s=i['label'].split(\"_\")\n",
    "        if len(s)>4:\n",
    "            s[3] = s[3] + \"_\" + s[4]\n",
    "        return similarData['data'][s[0]][s[1]][s[2]][s[3]]\n",
    "    if len(similarData)>0:\n",
    "        simiDiff = [(i, {'val': simi(i), 'dif': i['value']-simi(i)}) for i in thisLad['pri']]\n",
    "        simiDiff = sorted(simiDiff, reverse=True, key=lambda x: abs(x[1]['dif']))\n",
    "\n",
    "    def near(i):\n",
    "        s=i['label'].split(\"_\")\n",
    "        if len(s)>4:\n",
    "            s[3] = s[3] + \"_\" + s[4]\n",
    "        return nearbyAreaData['data'][s[0]][s[1]][s[2]][s[3]]\n",
    "    if len(nearbyAreaData)>0:\n",
    "        nearDiff = [(i, {'val': near(i), 'dif': i['value']-near(i)}) for i in thisLad['pri']]\n",
    "        nearDiff = sorted(nearDiff, reverse=True, key=lambda x: abs(x[1]['dif']))\n",
    "\n",
    "    nearTops = sorted([(lad['name'], lad['pri'][0]) for lad in lads if lad['name'] in [i[1] for i in nearbyArea if i[0]==thisLad['name']]], key=lambda x: abs(x[1]['locRank']))\n",
    "\n",
    "    ageBandChange = sorted([(i, thisLad['data']['age10yr']['value']['2011'][i]-thisLad['data']['age10yr']['value']['2001'][i]) for i in thisLad['data']['age10yr']['value']['2001'].keys()], \n",
    "           reverse=True, key=lambda x: x[1])\n",
    "\n",
    "    equalAgeChange = [lad['name'] for \n",
    "     lad in lads if (lad['parents'][0]['name'] == thisLad['parents'][0]['name']) \n",
    "     & (lad['data']['agemed']['value']['change']['all']==thisLad['data']['agemed']['value']['change']['all'])]\n",
    "    len(equalAgeChange)\n",
    "\n",
    "    # Find and refine stories\n",
    "    stories = []\n",
    "    stories=stories+[{**i, **{'type':['pop']}} for i in thisLad['pri'] if i['label'] == 'population_value_change_all']\n",
    "    stories=stories+[{**i, **{'type':['size']}} for i in thisLad['pri'] if ((abs(i['value'])/abs(i['2011'])>0.1)&(abs(i['value']) > 1))]\n",
    "    stories=stories+[{**i, **{'type':['locRank']}} for i in thisLad['pri'] if (abs(i['locRank']) < 4)&(abs(i['value']) > 0.5)]\n",
    "    stories=stories+[{**i, **{'type':['natRank']}} for i in thisLad['pri'] if (abs(i['natRank']) < 4)&(abs(i['value']) > 0.5)]\n",
    "    stories=stories+[{**i[0], **{'type':['couBuck']}} for i in couDiff if ((abs(i[1]['val'])>0.5) & (abs(i[0]['value'])>0.5) & (sign(i[1]['val'])!=sign(i[0]['value'])))]\n",
    "    stories=stories+[{**i[0], **{'type':['regBuck']}} for i in regDiff if ((abs(i[1]['val'])>0.5) & (abs(i[0]['value'])>0.5) & (sign(i[1]['val'])!=sign(i[0]['value'])))]\n",
    "    stories=stories+[{**i[0], **{'type':['nearBuck']}} for i in nearDiff if ((abs(i[1]['val'])>0.8) & (abs(i[0]['value'])>0.8) & (sign(i[1]['val'])!=sign(i[0]['value'])))]\n",
    "    stories=stories+[{**i[0], **{'type':['simiBuck']}} for i in simiDiff if ((abs(i[1]['val'])>0.8) & (abs(i[0]['value'])>0.8) & (sign(i[1]['val'])!=sign(i[0]['value'])))]\n",
    "    stories=stories+[{**i[0], **{'type':['couDiff']}} for i in couDiff if ((abs(i[1]['dif'])>2) & (sign(i[1]['val'])==sign(i[0]['value'])))]\n",
    "    stories=stories+[{**i[0], **{'type':['regDiff']}} for i in regDiff if ((abs(i[1]['dif'])>2) & (sign(i[1]['val'])==sign(i[0]['value'])))]\n",
    "    stories=stories+[{**i[0], **{'type':['nearDiff']}} for i in nearDiff if ((abs(i[1]['dif'])>2) & (sign(i[1]['val'])==sign(i[0]['value'])))]\n",
    "    stories=stories+[{**i[0], **{'type':['simiDiff']}} for i in simiDiff if ((abs(i[1]['dif'])>2) & (sign(i[1]['val'])==sign(i[0]['value'])))]\n",
    "    seen = set()\n",
    "    uniq = [item['label'] for item in stories if item['label'] in seen or seen.add(item['label'])]\n",
    "    listofdoubles = [[i for i in stories if i['label'] == uniqI] for uniqI in uniq]\n",
    "    multi = [{**double[0], **{'type': [item for sublist in [i['type'] for i in double] for item in sublist]}} for double in listofdoubles]\n",
    "    stories = [item for item in stories if item['label'] not in [i['label'] for i in multi]]\n",
    "    stories=stories+multi\n",
    "\n",
    "    storiesRefined =[]\n",
    "    notInc = ['density', 'age10yr', 'travel']\n",
    "    for i in stories:\n",
    "        if i['label'].split(\"_\")[0] not in notInc:\n",
    "            storiesRefined.append(i)\n",
    "            notInc.append(i['label'].split(\"_\")[0])\n",
    "\n",
    "    if (thisLad['code'][0]!='W'):\n",
    "        storiesRefined = sorted(storiesRefined, key=lambda x: ((topicScoresOrder[bbcRegLU[thisLad['code']]][x['label'].split('_')[0]])*(1/(1+abs(x['value'])))))\n",
    "    else:\n",
    "        storiesRefined = sorted(storiesRefined, key=lambda x: 1/(1+abs(x['value'])))\n",
    "\n",
    "    storiesRefined = sorted(storiesRefined, reverse=True, key=lambda x: abs(x['locRank'])<4)\n",
    "    storiesRefined = sorted(storiesRefined, reverse=True, key=lambda x: abs(x['natRank'])<4)\n",
    "    storiesRefined = sorted(storiesRefined, reverse=True, key=lambda x: abs(x['locRank'])<3)\n",
    "    storiesRefined = sorted(storiesRefined, reverse=True, key=lambda x: abs(x['natRank'])<3)\n",
    "    storiesRefined = sorted(storiesRefined, reverse=True, key=lambda x: x['type']=='regBuck')\n",
    "    storiesRefined = sorted(storiesRefined, reverse=True, key=lambda x: x['type']=='couBuck')\n",
    "    # storiesRefined = storiesRefined[:6]\n",
    "    storiesRefined = sorted(storiesRefined, reverse=True, key=lambda x: x['label']=='agemed_value_change_all')\n",
    "    storiesRefined = sorted(storiesRefined, reverse=True, key=lambda x: x['label']=='population_value_change_all')\n",
    "\n",
    "    \n",
    "    # Create a varibale 'hiRank' which holds the index of a top 5 rank at the national or reginal level to be used for an overtake story\n",
    "    hiRank ={}\n",
    "    hiRankNat = []\n",
    "    for i in storiesRefined:\n",
    "        if i['label'] not in ['population_value_change_all', 'agemed_value_change_all']:\n",
    "            s=i['label'].split(\"_\")\n",
    "            if len(s)>4:\n",
    "                s[3] = s[3] + \"_\" + s[4]\n",
    "            if thisLad['data'][s[0]][s[1]+\"_rank\"]['2011'][s[3]]!=thisLad['data'][s[0]][s[1]+\"_rank\"]['2001'][s[3]]:\n",
    "                hiRankNat.append(abs(thisLad['data'][s[0]][s[1]+\"_rank\"]['2011'][s[3]]))\n",
    "            else:\n",
    "                hiRankNat.append(100)\n",
    "        else:\n",
    "            hiRankNat.append(100)\n",
    "\n",
    "    hiRankReg = []\n",
    "    for i in storiesRefined:\n",
    "        if i['label'] not in ['population_value_change_all', 'agemed_value_change_all']:\n",
    "            s=i['label'].split(\"_\")\n",
    "            if len(s)>4:\n",
    "                s[3] = s[3] + \"_\" + s[4]\n",
    "            if thisLad['data'][s[0]][s[1]+\"_rank_local\"]['2011'][s[3]]!=thisLad['data'][s[0]][s[1]+\"_rank_local\"]['2001'][s[3]]:\n",
    "                hiRankReg.append(abs(thisLad['data'][s[0]][s[1]+\"_rank_local\"]['2011'][s[3]]))\n",
    "            else:\n",
    "                hiRankReg.append(100)\n",
    "        else:\n",
    "            hiRankReg.append(100)\n",
    "            \n",
    "    if min(hiRankNat)<5:\n",
    "        hiRank['rankIn'] = hiRankNat.index(min(hiRankNat))\n",
    "        hiRank['type'] = 'nat'\n",
    "    elif min(hiRankReg)<5:\n",
    "        hiRank['rankIn'] = hiRankReg.index(min(hiRankReg))\n",
    "        hiRank['type'] = 'reg'\n",
    "    elif min(hiRankNat)<10:\n",
    "        hiRank['rankIn'] = hiRankNat.index(min(hiRankNat))\n",
    "        hiRank['type'] = 'nat'\n",
    "    else:\n",
    "        hiRank['rankIn'] = \"None\"\n",
    "        hiRank['type'] = \"None\"\n",
    "\n",
    "    ageBandChange= [i for i in ageBandChange if i[0]!='all']\n",
    "    ageBandPos = sorted([i for i in ageBandChange if i[1]>0], reverse=True, key=lambda x: abs(x[1]))\n",
    "    ageBandNeg = sorted([i for i in ageBandChange if i[1]<0], reverse=True, key=lambda x: abs(x[1]))\n",
    "\n",
    "    # Add data to object\n",
    "    thisLad['hiRank']=hiRank\n",
    "    thisLad['stories'] = storiesRefined\n",
    "    thisLad['similar'] = similarData\n",
    "    thisLad['nearbyArea'] = {}\n",
    "    thisLad['nearbyArea']['triples'] = nearbyArea\n",
    "    thisLad['nearbyArea']['nearTops'] = nearTops\n",
    "    thisLad['nearbyArea']['nearTops'] = nearbyAreaData\n",
    "    thisLad['differences'] = {}\n",
    "    thisLad['differences']['country'] = couDiff\n",
    "    thisLad['differences']['region'] = regDiff\n",
    "    thisLad['differences']['near'] = nearDiff\n",
    "    thisLad['data']['age10yr']['absChange'] = {}\n",
    "    thisLad['data']['age10yr']['absChange']['pos'] = ageBandPos\n",
    "    thisLad['data']['age10yr']['absChange']['neg'] = ageBandNeg\n",
    "    thisLad['data']['agemed']['value_rank_local']['equalAgeChange]'] = len(equalAgeChange)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Similar data not found for::  Bournemouth, Christchurch and Poole\n",
      "Similar data not found for::  Cornwall\n",
      "Nearby data not found for::  Isles of Scilly\n",
      "Similar data not found for::  Isles of Scilly\n",
      "Similar data not found for::  East Suffolk\n",
      "Similar data not found for::  West Suffolk\n",
      "Similar data not found for::  North Northamptonshire\n",
      "Similar data not found for::  Dorset\n",
      "Similar data not found for::  Somerset West and Taunton\n",
      "Similar data not found for::  West Northamptonshire\n",
      "Similar data not found for::  Buckinghamshire\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "source": [
    "this(\"Copeland\")['stories']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'label': 'population_value_change_all',\n",
       "  'locRank': -11,\n",
       "  'natRank': -29,\n",
       "  'value': 1.85,\n",
       "  '2011': 503127.0,\n",
       "  'type': ['pop', 'nearBuck', 'couDiff', 'regDiff']},\n",
       " {'label': 'agemed_value_change_all',\n",
       "  'locRank': 1,\n",
       "  'natRank': 3,\n",
       "  'value': 5.0,\n",
       "  '2011': 29.0,\n",
       "  'type': ['size', 'locRank', 'natRank', 'couDiff', 'regDiff']},\n",
       " {'label': 'economic_perc_change_unemployed',\n",
       "  'locRank': -1,\n",
       "  'natRank': -1,\n",
       "  'value': -0.78,\n",
       "  '2011': 5.71,\n",
       "  'type': ['locRank', 'natRank', 'couBuck', 'regBuck']},\n",
       " {'label': 'hoursworked_perc_change_Male1-15',\n",
       "  'locRank': -1,\n",
       "  'natRank': -21,\n",
       "  'value': 0.76,\n",
       "  '2011': 4.5,\n",
       "  'type': ['locRank']},\n",
       " {'label': 'religion_perc_change_Christian',\n",
       "  'locRank': 3,\n",
       "  'natRank': 10,\n",
       "  'value': -7.44,\n",
       "  '2011': 48.74,\n",
       "  'type': ['size', 'locRank', 'couDiff', 'regDiff', 'nearDiff', 'simiDiff']},\n",
       " {'label': 'tenure_perc_change_rented_social',\n",
       "  'locRank': -3,\n",
       "  'natRank': -19,\n",
       "  'value': -4.41,\n",
       "  '2011': 31.56,\n",
       "  'type': ['size', 'locRank', 'couDiff', 'regDiff', 'nearDiff', 'simiDiff']},\n",
       " {'label': 'health_perc_change_bad',\n",
       "  'locRank': 5,\n",
       "  'natRank': -123,\n",
       "  'value': -3.5,\n",
       "  '2011': 7.09,\n",
       "  'type': ['size']},\n",
       " {'label': 'marital_perc_change_Married',\n",
       "  'locRank': 4,\n",
       "  'natRank': 62,\n",
       "  'value': -2.9,\n",
       "  '2011': 29.71,\n",
       "  'type': ['nearDiff']},\n",
       " {'label': 'children_perc_change_Kids',\n",
       "  'locRank': -7,\n",
       "  'natRank': -17,\n",
       "  'value': -2.76,\n",
       "  '2011': 28.45,\n",
       "  'type': ['couDiff']},\n",
       " {'label': 'household_perc_change_Cohabiting',\n",
       "  'locRank': 5,\n",
       "  'natRank': 21,\n",
       "  'value': 2.52,\n",
       "  '2011': 10.9,\n",
       "  'type': ['size']},\n",
       " {'label': 'ethnicity_perc_change_asian',\n",
       "  'locRank': -17,\n",
       "  'natRank': -83,\n",
       "  'value': 0.58,\n",
       "  '2011': 17.09,\n",
       "  'type': ['couDiff']}]"
      ]
     },
     "metadata": {},
     "execution_count": 501
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "source": [
    "similarData['name'] = this('Somerset West and Taunton')['name']\n",
    "similarData['data'] = this('Somerset West and Taunton')['data']\n",
    "\n",
    "this('Dorset')['similar'] = similarData\n",
    "\n",
    "\n",
    "similarData['name'] = this('Dorset')['name']\n",
    "similarData['data'] = this('Dorset')['data']\n",
    "\n",
    "this('Somerset West and Taunton')['similar'] = similarData\n",
    "\n",
    "\n",
    "similarData['name'] = this('West Devon')['name']\n",
    "similarData['data'] = this('West Devon')['data']\n",
    "\n",
    "this('Cornwall')['similar'] = similarData\n",
    "\n",
    "\n",
    "similarData['name'] = this('Buckinghamshire')['name']\n",
    "similarData['data'] = this('Buckinghamshire')['data']\n",
    "\n",
    "this('East Suffolk')['similar'] = similarData\n",
    "\n",
    "\n",
    "similarData['name'] = this('East Suffolk')['name']\n",
    "similarData['data'] = this('East Suffolk')['data']\n",
    "\n",
    "this('Buckinghamshire')['similar'] = similarData\n",
    "\n",
    "\n",
    "similarData['name'] = this('Bournemouth, Christchurch and Poole')['name']\n",
    "similarData['data'] = this('Bournemouth, Christchurch and Poole')['data']\n",
    "\n",
    "this('West Suffolk')['similar'] = similarData\n",
    "\n",
    "similarData['name'] = this('West Suffolk')['name']\n",
    "similarData['data'] = this('West Suffolk')['data']\n",
    "\n",
    "this('Bournemouth, Christchurch and Poole')['similar'] = similarData\n",
    "\n",
    "similarData['name'] = this('North Northamptonshire')['name']\n",
    "similarData['data'] = this('North Northamptonshire')['data']\n",
    "\n",
    "this('West Northamptonshire')['similar'] = similarData\n",
    "\n",
    "\n",
    "similarData['name'] = this('West Northamptonshire')['name']\n",
    "similarData['data'] = this('West Northamptonshire')['data']\n",
    "\n",
    "this('North Northamptonshire')['similar'] = similarData\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "source": [
    "for region in regions:\n",
    "    region['data']['welsh'] = {}\n",
    "    region['data']['welsh']['perc'] = {}\n",
    "    region['data']['welsh']['value'] = {}\n",
    "    for k in region['data']['welsh'].keys():\n",
    "        region['data']['welsh'][k]['2001'] = {}\n",
    "        region['data']['welsh'][k]['2011'] = {}\n",
    "        region['data']['welsh'][k]['change'] = {}\n",
    "        for j in region['data']['welsh'][k].keys():\n",
    "            region['data']['welsh'][k][j]['SpeaksWelsh'] = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "source": [
    "for rgn in regions:\n",
    "    try:\n",
    "        with open('/Users/theojolliffe/Documents/Area Reports/census-data-transformed/json/place/'+rgn['code']+'.json', 'w') as outfile:\n",
    "            json.dump(rgn, outfile)\n",
    "    except:\n",
    "        print(\"Failed: \", rgn['name'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "source": [
    "for ctry in countries:\n",
    "    try:\n",
    "        with open('/Users/theojolliffe/Documents/Area Reports/census-data-transformed/json/place/'+ctry['code']+'.json', 'w') as outfile:\n",
    "            json.dump(ctry, outfile)\n",
    "    except:\n",
    "        print(\"Failed: \", ctry['name'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "source": [
    "for lad in lads:\n",
    "    try:\n",
    "        with open('/Users/theojolliffe/Documents/Area Reports/census-data-transformed/json/place/'+lad['code']+'.json', 'w') as outfile:\n",
    "            json.dump(lad, outfile)\n",
    "    except:\n",
    "        print(\"Failed: \", lad['name'])\n"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "source": [
    "this(\"City of London\")['gss']['short'] = 'city'\n",
    "this(\"City of London\")['gss']['long'] = 'City of London'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "source": [
    "!git add .\n",
    "!git commit -m \"Add files\"\n",
    "!git push -u origin main"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[main 4e70a48c] Add files\n",
      " 331 files changed, 331 insertions(+), 331 deletions(-)\n",
      " rewrite json/place/E06000001.json (92%)\n",
      " rewrite json/place/E06000002.json (93%)\n",
      " rewrite json/place/E06000003.json (91%)\n",
      " rewrite json/place/E06000004.json (92%)\n",
      " rewrite json/place/E06000005.json (90%)\n",
      " rewrite json/place/E06000006.json (92%)\n",
      " rewrite json/place/E06000007.json (92%)\n",
      " rewrite json/place/E06000008.json (92%)\n",
      " rewrite json/place/E06000009.json (93%)\n",
      " rewrite json/place/E06000010.json (92%)\n",
      " rewrite json/place/E06000011.json (91%)\n",
      " rewrite json/place/E06000012.json (92%)\n",
      " rewrite json/place/E06000013.json (91%)\n",
      " rewrite json/place/E06000014.json (67%)\n",
      " rewrite json/place/E06000015.json (93%)\n",
      " rewrite json/place/E06000016.json (92%)\n",
      " rewrite json/place/E06000017.json (70%)\n",
      " rewrite json/place/E06000018.json (92%)\n",
      " rewrite json/place/E06000019.json (92%)\n",
      " rewrite json/place/E06000020.json (93%)\n",
      " rewrite json/place/E06000021.json (92%)\n",
      " rewrite json/place/E06000022.json (65%)\n",
      " rewrite json/place/E06000023.json (92%)\n",
      " rewrite json/place/E06000024.json (92%)\n",
      " rewrite json/place/E06000025.json (91%)\n",
      " rewrite json/place/E06000026.json (68%)\n",
      " rewrite json/place/E06000027.json (91%)\n",
      " rewrite json/place/E06000030.json (93%)\n",
      " rewrite json/place/E06000031.json (93%)\n",
      " rewrite json/place/E06000032.json (93%)\n",
      " rewrite json/place/E06000033.json (92%)\n",
      " rewrite json/place/E06000034.json (93%)\n",
      " rewrite json/place/E06000035.json (92%)\n",
      " rewrite json/place/E06000036.json (92%)\n",
      " rewrite json/place/E06000037.json (92%)\n",
      " rewrite json/place/E06000038.json (93%)\n",
      " rewrite json/place/E06000039.json (93%)\n",
      " rewrite json/place/E06000040.json (93%)\n",
      " rewrite json/place/E06000041.json (90%)\n",
      " rewrite json/place/E06000042.json (93%)\n",
      " rewrite json/place/E06000043.json (93%)\n",
      " rewrite json/place/E06000044.json (94%)\n",
      " rewrite json/place/E06000045.json (92%)\n",
      " rewrite json/place/E06000046.json (92%)\n",
      " rewrite json/place/E06000047.json (93%)\n",
      " rewrite json/place/E06000049.json (92%)\n",
      " rewrite json/place/E06000050.json (92%)\n",
      " rewrite json/place/E06000051.json (92%)\n",
      " rewrite json/place/E06000052.json (91%)\n",
      " rewrite json/place/E06000053.json (93%)\n",
      " rewrite json/place/E06000054.json (92%)\n",
      " rewrite json/place/E06000055.json (93%)\n",
      " rewrite json/place/E06000056.json (92%)\n",
      " rewrite json/place/E06000057.json (93%)\n",
      " rewrite json/place/E06000058.json (93%)\n",
      " rewrite json/place/E06000059.json (92%)\n",
      " rewrite json/place/E06000060.json (91%)\n",
      " rewrite json/place/E06000061.json (93%)\n",
      " rewrite json/place/E06000062.json (92%)\n",
      " rewrite json/place/E07000008.json (92%)\n",
      " rewrite json/place/E07000009.json (93%)\n",
      " rewrite json/place/E07000010.json (93%)\n",
      " rewrite json/place/E07000011.json (92%)\n",
      " rewrite json/place/E07000012.json (93%)\n",
      " rewrite json/place/E07000026.json (93%)\n",
      " rewrite json/place/E07000027.json (93%)\n",
      " rewrite json/place/E07000028.json (93%)\n",
      " rewrite json/place/E07000029.json (93%)\n",
      " rewrite json/place/E07000030.json (93%)\n",
      " rewrite json/place/E07000031.json (93%)\n",
      " rewrite json/place/E07000032.json (90%)\n",
      " rewrite json/place/E07000033.json (93%)\n",
      " rewrite json/place/E07000034.json (93%)\n",
      " rewrite json/place/E07000035.json (92%)\n",
      " rewrite json/place/E07000036.json (91%)\n",
      " rewrite json/place/E07000037.json (92%)\n",
      " rewrite json/place/E07000038.json (92%)\n",
      " rewrite json/place/E07000039.json (93%)\n",
      " rewrite json/place/E07000040.json (92%)\n",
      " rewrite json/place/E07000041.json (93%)\n",
      " rewrite json/place/E07000042.json (92%)\n",
      " rewrite json/place/E07000043.json (93%)\n",
      " rewrite json/place/E07000044.json (92%)\n",
      " rewrite json/place/E07000045.json (93%)\n",
      " rewrite json/place/E07000046.json (91%)\n",
      " rewrite json/place/E07000047.json (92%)\n",
      " rewrite json/place/E07000061.json (92%)\n",
      " rewrite json/place/E07000062.json (93%)\n",
      " rewrite json/place/E07000063.json (93%)\n",
      " rewrite json/place/E07000064.json (93%)\n",
      " rewrite json/place/E07000065.json (93%)\n",
      " rewrite json/place/E07000066.json (92%)\n",
      " rewrite json/place/E07000067.json (93%)\n",
      " rewrite json/place/E07000068.json (93%)\n",
      " rewrite json/place/E07000069.json (92%)\n",
      " rewrite json/place/E07000070.json (91%)\n",
      " rewrite json/place/E07000071.json (68%)\n",
      " rewrite json/place/E07000072.json (92%)\n",
      " rewrite json/place/E07000073.json (92%)\n",
      " rewrite json/place/E07000074.json (93%)\n",
      " rewrite json/place/E07000075.json (92%)\n",
      " rewrite json/place/E07000076.json (93%)\n",
      " rewrite json/place/E07000077.json (92%)\n",
      " rewrite json/place/E07000078.json (91%)\n",
      " rewrite json/place/E07000079.json (91%)\n",
      " rewrite json/place/E07000080.json (93%)\n",
      " rewrite json/place/E07000081.json (93%)\n",
      " rewrite json/place/E07000082.json (93%)\n",
      " rewrite json/place/E07000083.json (93%)\n",
      " rewrite json/place/E07000084.json (68%)\n",
      " rewrite json/place/E07000085.json (92%)\n",
      " rewrite json/place/E07000086.json (92%)\n",
      " rewrite json/place/E07000087.json (94%)\n",
      " rewrite json/place/E07000088.json (93%)\n",
      " rewrite json/place/E07000089.json (92%)\n",
      " rewrite json/place/E07000090.json (92%)\n",
      " rewrite json/place/E07000091.json (93%)\n",
      " rewrite json/place/E07000092.json (93%)\n",
      " rewrite json/place/E07000093.json (93%)\n",
      " rewrite json/place/E07000094.json (92%)\n",
      " rewrite json/place/E07000095.json (92%)\n",
      " rewrite json/place/E07000096.json (91%)\n",
      " rewrite json/place/E07000098.json (92%)\n",
      " rewrite json/place/E07000099.json (93%)\n",
      " rewrite json/place/E07000102.json (91%)\n",
      " rewrite json/place/E07000103.json (68%)\n",
      " rewrite json/place/E07000105.json (91%)\n",
      " rewrite json/place/E07000106.json (93%)\n",
      " rewrite json/place/E07000107.json (92%)\n",
      " rewrite json/place/E07000108.json (92%)\n",
      " rewrite json/place/E07000109.json (93%)\n",
      " rewrite json/place/E07000110.json (93%)\n",
      " rewrite json/place/E07000111.json (92%)\n",
      " rewrite json/place/E07000112.json (91%)\n",
      " rewrite json/place/E07000113.json (92%)\n",
      " rewrite json/place/E07000114.json (92%)\n",
      " rewrite json/place/E07000115.json (92%)\n",
      " rewrite json/place/E07000116.json (93%)\n",
      " rewrite json/place/E07000117.json (92%)\n",
      " rewrite json/place/E07000118.json (94%)\n",
      " rewrite json/place/E07000119.json (93%)\n",
      " rewrite json/place/E07000120.json (92%)\n",
      " rewrite json/place/E07000121.json (93%)\n",
      " rewrite json/place/E07000122.json (92%)\n",
      " rewrite json/place/E07000123.json (91%)\n",
      " rewrite json/place/E07000124.json (68%)\n",
      " rewrite json/place/E07000125.json (93%)\n",
      " rewrite json/place/E07000126.json (92%)\n",
      " rewrite json/place/E07000127.json (93%)\n",
      " rewrite json/place/E07000128.json (89%)\n",
      " rewrite json/place/E07000129.json (93%)\n",
      " rewrite json/place/E07000130.json (94%)\n",
      " rewrite json/place/E07000131.json (93%)\n",
      " rewrite json/place/E07000132.json (93%)\n",
      " rewrite json/place/E07000133.json (92%)\n",
      " rewrite json/place/E07000134.json (93%)\n",
      " rewrite json/place/E07000135.json (93%)\n",
      " rewrite json/place/E07000136.json (93%)\n",
      " rewrite json/place/E07000137.json (92%)\n",
      " rewrite json/place/E07000138.json (92%)\n",
      " rewrite json/place/E07000139.json (92%)\n",
      " rewrite json/place/E07000140.json (92%)\n",
      " rewrite json/place/E07000141.json (93%)\n",
      " rewrite json/place/E07000142.json (92%)\n",
      " rewrite json/place/E07000143.json (92%)\n",
      " rewrite json/place/E07000144.json (92%)\n",
      " rewrite json/place/E07000145.json (92%)\n",
      " rewrite json/place/E07000146.json (93%)\n",
      " rewrite json/place/E07000147.json (93%)\n",
      " rewrite json/place/E07000148.json (88%)\n",
      " rewrite json/place/E07000149.json (93%)\n",
      " rewrite json/place/E07000163.json (92%)\n",
      " rewrite json/place/E07000164.json (92%)\n",
      " rewrite json/place/E07000165.json (91%)\n",
      " rewrite json/place/E07000166.json (92%)\n",
      " rewrite json/place/E07000167.json (92%)\n",
      " rewrite json/place/E07000168.json (94%)\n",
      " rewrite json/place/E07000169.json (91%)\n",
      " rewrite json/place/E07000170.json (92%)\n",
      " rewrite json/place/E07000171.json (69%)\n",
      " rewrite json/place/E07000172.json (92%)\n",
      " rewrite json/place/E07000173.json (92%)\n",
      " rewrite json/place/E07000174.json (93%)\n",
      " rewrite json/place/E07000175.json (92%)\n",
      " rewrite json/place/E07000176.json (92%)\n",
      " rewrite json/place/E07000177.json (93%)\n",
      " rewrite json/place/E07000178.json (91%)\n",
      " rewrite json/place/E07000179.json (93%)\n",
      " rewrite json/place/E07000180.json (92%)\n",
      " rewrite json/place/E07000181.json (93%)\n",
      " rewrite json/place/E07000187.json (93%)\n",
      " rewrite json/place/E07000188.json (91%)\n",
      " rewrite json/place/E07000189.json (92%)\n",
      " rewrite json/place/E07000192.json (92%)\n",
      " rewrite json/place/E07000193.json (93%)\n",
      " rewrite json/place/E07000194.json (94%)\n",
      " rewrite json/place/E07000195.json (91%)\n",
      " rewrite json/place/E07000196.json (93%)\n",
      " rewrite json/place/E07000197.json (92%)\n",
      " rewrite json/place/E07000198.json (92%)\n",
      " rewrite json/place/E07000199.json (90%)\n",
      " rewrite json/place/E07000200.json (93%)\n",
      " rewrite json/place/E07000202.json (93%)\n",
      " rewrite json/place/E07000203.json (92%)\n",
      " rewrite json/place/E07000207.json (93%)\n",
      " rewrite json/place/E07000208.json (94%)\n",
      " rewrite json/place/E07000209.json (92%)\n",
      " rewrite json/place/E07000210.json (93%)\n",
      " rewrite json/place/E07000211.json (93%)\n",
      " rewrite json/place/E07000212.json (92%)\n",
      " rewrite json/place/E07000213.json (91%)\n",
      " rewrite json/place/E07000214.json (90%)\n",
      " rewrite json/place/E07000215.json (92%)\n",
      " rewrite json/place/E07000216.json (93%)\n",
      " rewrite json/place/E07000217.json (91%)\n",
      " rewrite json/place/E07000218.json (94%)\n",
      " rewrite json/place/E07000219.json (65%)\n",
      " rewrite json/place/E07000220.json (92%)\n",
      " rewrite json/place/E07000221.json (93%)\n",
      " rewrite json/place/E07000222.json (94%)\n",
      " rewrite json/place/E07000223.json (92%)\n",
      " rewrite json/place/E07000224.json (92%)\n",
      " rewrite json/place/E07000225.json (93%)\n",
      " rewrite json/place/E07000226.json (93%)\n",
      " rewrite json/place/E07000227.json (93%)\n",
      " rewrite json/place/E07000228.json (91%)\n",
      " rewrite json/place/E07000229.json (92%)\n",
      " rewrite json/place/E07000234.json (92%)\n",
      " rewrite json/place/E07000235.json (93%)\n",
      " rewrite json/place/E07000236.json (92%)\n",
      " rewrite json/place/E07000237.json (94%)\n",
      " rewrite json/place/E07000238.json (94%)\n",
      " rewrite json/place/E07000239.json (90%)\n",
      " rewrite json/place/E07000240.json (92%)\n",
      " rewrite json/place/E07000241.json (92%)\n",
      " rewrite json/place/E07000242.json (92%)\n",
      " rewrite json/place/E07000243.json (91%)\n",
      " rewrite json/place/E07000244.json (91%)\n",
      " rewrite json/place/E07000245.json (93%)\n",
      " rewrite json/place/E07000246.json (93%)\n",
      " rewrite json/place/E08000001.json (93%)\n",
      " rewrite json/place/E08000002.json (89%)\n",
      " rewrite json/place/E08000003.json (91%)\n",
      " rewrite json/place/E08000004.json (92%)\n",
      " rewrite json/place/E08000005.json (93%)\n",
      " rewrite json/place/E08000006.json (92%)\n",
      " rewrite json/place/E08000007.json (93%)\n",
      " rewrite json/place/E08000008.json (93%)\n",
      " rewrite json/place/E08000009.json (92%)\n",
      " rewrite json/place/E08000010.json (92%)\n",
      " rewrite json/place/E08000011.json (93%)\n",
      " rewrite json/place/E08000012.json (91%)\n",
      " rewrite json/place/E08000013.json (91%)\n",
      " rewrite json/place/E08000014.json (92%)\n",
      " rewrite json/place/E08000015.json (93%)\n",
      " rewrite json/place/E08000016.json (90%)\n",
      " rewrite json/place/E08000017.json (92%)\n",
      " rewrite json/place/E08000018.json (91%)\n",
      " rewrite json/place/E08000019.json (92%)\n",
      " rewrite json/place/E08000021.json (93%)\n",
      " rewrite json/place/E08000022.json (93%)\n",
      " rewrite json/place/E08000023.json (90%)\n",
      " rewrite json/place/E08000024.json (90%)\n",
      " rewrite json/place/E08000025.json (89%)\n",
      " rewrite json/place/E08000026.json (93%)\n",
      " rewrite json/place/E08000027.json (93%)\n",
      " rewrite json/place/E08000028.json (91%)\n",
      " rewrite json/place/E08000029.json (93%)\n",
      " rewrite json/place/E08000030.json (91%)\n",
      " rewrite json/place/E08000031.json (91%)\n",
      " rewrite json/place/E08000032.json (91%)\n",
      " rewrite json/place/E08000033.json (92%)\n",
      " rewrite json/place/E08000034.json (93%)\n",
      " rewrite json/place/E08000035.json (90%)\n",
      " rewrite json/place/E08000036.json (90%)\n",
      " rewrite json/place/E08000037.json (94%)\n",
      " rewrite json/place/E09000001.json (93%)\n",
      " rewrite json/place/E09000002.json (93%)\n",
      " rewrite json/place/E09000003.json (90%)\n",
      " rewrite json/place/E09000004.json (92%)\n",
      " rewrite json/place/E09000005.json (89%)\n",
      " rewrite json/place/E09000006.json (92%)\n",
      " rewrite json/place/E09000007.json (92%)\n",
      " rewrite json/place/E09000008.json (91%)\n",
      " rewrite json/place/E09000009.json (92%)\n",
      " rewrite json/place/E09000010.json (92%)\n",
      " rewrite json/place/E09000011.json (93%)\n",
      " rewrite json/place/E09000012.json (91%)\n",
      " rewrite json/place/E09000013.json (90%)\n",
      " rewrite json/place/E09000014.json (90%)\n",
      " rewrite json/place/E09000015.json (91%)\n",
      " rewrite json/place/E09000016.json (89%)\n",
      " rewrite json/place/E09000017.json (90%)\n",
      " rewrite json/place/E09000018.json (92%)\n",
      " rewrite json/place/E09000019.json (92%)\n",
      " rewrite json/place/E09000020.json (68%)\n",
      " rewrite json/place/E09000021.json (92%)\n",
      " rewrite json/place/E09000022.json (92%)\n",
      " rewrite json/place/E09000023.json (91%)\n",
      " rewrite json/place/E09000024.json (92%)\n",
      " rewrite json/place/E09000025.json (86%)\n",
      " rewrite json/place/E09000026.json (92%)\n",
      " rewrite json/place/E09000027.json (92%)\n",
      " rewrite json/place/E09000028.json (91%)\n",
      " rewrite json/place/E09000029.json (92%)\n",
      " rewrite json/place/E09000030.json (92%)\n",
      " rewrite json/place/E09000031.json (93%)\n",
      " rewrite json/place/E09000032.json (92%)\n",
      " rewrite json/place/E09000033.json (92%)\n",
      " rewrite json/place/W06000001.json (94%)\n",
      " rewrite json/place/W06000002.json (90%)\n",
      " rewrite json/place/W06000003.json (93%)\n",
      " rewrite json/place/W06000004.json (91%)\n",
      " rewrite json/place/W06000005.json (92%)\n",
      " rewrite json/place/W06000006.json (92%)\n",
      " rewrite json/place/W06000008.json (91%)\n",
      " rewrite json/place/W06000009.json (92%)\n",
      " rewrite json/place/W06000010.json (92%)\n",
      " rewrite json/place/W06000011.json (93%)\n",
      " rewrite json/place/W06000012.json (92%)\n",
      " rewrite json/place/W06000013.json (69%)\n",
      " rewrite json/place/W06000014.json (93%)\n",
      " rewrite json/place/W06000015.json (93%)\n",
      " rewrite json/place/W06000016.json (91%)\n",
      " rewrite json/place/W06000018.json (93%)\n",
      " rewrite json/place/W06000019.json (93%)\n",
      " rewrite json/place/W06000020.json (91%)\n",
      " rewrite json/place/W06000021.json (90%)\n",
      " rewrite json/place/W06000022.json (91%)\n",
      " rewrite json/place/W06000023.json (94%)\n",
      " rewrite json/place/W06000024.json (93%)\n",
      "Enumerating objects: 572, done.\n",
      "Counting objects: 100% (572/572), done.\n",
      "Delta compression using up to 16 threads\n",
      "Compressing objects: 100% (335/335), done.\n",
      "Writing objects: 100% (335/335), 3.81 MiB | 916.00 KiB/s, done.\n",
      "Total 335 (delta 333), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (333/333), completed with 236 local objects.\u001b[K\n",
      "To https://github.com/theojolliffe/census-data.git\n",
      "   5ddd86a4..4e70a48c  main -> main\n",
      "Branch 'main' set up to track remote branch 'main' from 'origin'.\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!pwd"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/Users/theojolliffe/Documents/census-data-transformed\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "df[df['topic'].split(\"_\")[0] == 'care']"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'split'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-4e7352f16a17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'topic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'care'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'split'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "cea7541316ff5a5331e52731c94cf74070367f803d180639f9ebf31b0fd7617a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}